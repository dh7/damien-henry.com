[
  {
    "pageId": "https://petalite-process-508.notion.site/Damien-Henry-11f133e867094e29bc5d0107782bb960",
    "slug": "/",
    "title": "Home",
    "content": "Damien Henry\n\ndh_lab.jpg\n\nI grew up in the countryside in France where I taught myself to code. I studied signal analysis and worked for the industry but soon was attracted by entrepreneurship.\n\nIn 2007, I became the first CTO of¬† Voxler . Our singing voice analysis technology powered 10+ video games.\n\nIn 2011, I co-founded¬† AudioGaming  where I created an optimized, memory-efficient, audio synthesis framework in C. The next year we pivoted and created¬† Novelab , which became an award-winning studio for creating experiences in VR.\n\nIn 2013, I created a VR headset in Cardboard that became the¬† Google Cardboard , and joined Google in 2014. I oversaw innovation for six years at¬† Google Arts & Culture Lab , focusing my team on¬† AI/ML . During this period, I invested my time in deep-learning explorations and worked on  video generation  and  text analysis , among other things.\n\nIn 2020, I co-founded¬† Clipdrop . We launched¬† Clipdrop.co ¬†&¬† cleanup.pictures . We sold to  Stability.ai  in Feb 2023. We are now part of  Jasper  where I‚Äôm Image research SVP.\n\nI've always been hyperactive and enjoyed creating things for fun‚Äîit helps me keep learning. Below, you'll find some of these projects along with my writings and some book summaries.\n\nUntitled notebook.wav Audio generated by  NotebookML  from Damien Henry website content (no supervision)\n\nSummary & Bio\n\nAwards\n\nAFK\n\nMachine Learning & AI\n\nGoogle Cardboard\n\nFix-typos.com\n\n20 Watts\n\nReading\n\nWriting"
  },
  {
    "pageId": "11f133e8-6709-4e29-bc5d-0107782bb960",
    "slug": "damien-henry",
    "title": "Damien Henry",
    "content": "Damien Henry\n\ndh_lab.jpg\n\nI grew up in the countryside in France where I taught myself to code. I studied signal analysis and worked for the industry but soon was attracted by entrepreneurship.\n\nIn 2007, I became the first CTO of¬† Voxler . Our singing voice analysis technology powered 10+ video games.\n\nIn 2011, I co-founded¬† AudioGaming  where I created an optimized, memory-efficient, audio synthesis framework in C. The next year we pivoted and created¬† Novelab , which became an award-winning studio for creating experiences in VR.\n\nIn 2013, I created a VR headset in Cardboard that became the¬† Google Cardboard , and joined Google in 2014. I oversaw innovation for six years at¬† Google Arts & Culture Lab , focusing my team on¬† AI/ML . During this period, I invested my time in deep-learning explorations and worked on  video generation  and  text analysis , among other things.\n\nIn 2020, I co-founded¬† Clipdrop . We launched¬† Clipdrop.co ¬†&¬† cleanup.pictures . We sold to  Stability.ai  in Feb 2023. We are now part of  Jasper  where I‚Äôm Image research SVP.\n\nI've always been hyperactive and enjoyed creating things for fun‚Äîit helps me keep learning. Below, you'll find some of these projects along with my writings and some book summaries.\n\nUntitled notebook.wav Audio generated by  NotebookML  from Damien Henry website content (no supervision)\n\nSummary & Bio\n\nAwards\n\nAFK\n\nMachine Learning & AI\n\nGoogle Cardboard\n\nFix-typos.com\n\n20 Watts\n\nReading\n\nWriting"
  },
  {
    "pageId": "5a8e51ae-aaed-4620-9eac-e830b0af77c2",
    "slug": "summary-bio",
    "title": "Summary & Bio",
    "content": "Summary & Bio\n\nDamien Henry\n\nDamien Henry is Senior Vice President of Image Research at  Jasper.ai . He co-founded Init ML, the company behind  Clipdrop  and  cleanup.pictures , which was acquired by Stability.ai in 2023 and later became part of Jasper.\n\nEarlier, Damien spent six years leading innovation at the  Google Arts & Culture Lab , where his team pioneered applications of AI/ML in creativity, including experiments in video generation and text analysis. In 2013, he co-created the prototype that became  Google Cardboard , Google‚Äôs low-cost VR headset.\n\nBefore Google, Damien co-founded  AudioGaming  and  Novelab , building award-winning VR and interactive experiences, and served as the first CTO of  Voxler , powering music games with singing voice analysis.\n\nDamien holds an engineering degree in signal analysis, is a co-author of 10 patents, and has won multiple world-class awards throughout his career. A lifelong creator, he continues to explore how technology, AI, and design intersect to open new possibilities\n\nShort bio\n\nDamien Henry is Image Research SVP at Jasper.ai. He co-founded Init ML, creators of  Clipdrop  and  cleanup.pictures , acquired by Stability.ai in 2023.\n\nPreviously, he led innovation at the  Google Arts & Culture Lab , co-created  Google Cardboard , and co-founded  AudioGaming  and  Novelab .\n\nDamien holds 10 patents, has earned multiple global awards, and is passionate about building at the intersection of AI, design, and creativity.\n\nShort short bio\n\nDamien Henry is SVP of Image Research at  Jasper.ai , co-founder of Clipdrop, and co-creator of Google Cardboard. He has led innovation at Google Arts & Culture Lab, and builds at the intersection of AI and creativity.\n\nProfessional   Experiences\n\nSenior Vice President Image Research,   Jasper.ai\n\nSenior Vice President of Product,  Stability.ai ,\n\nCo-founder and COO for  Init ML:  ClipDrop.co , acquired by  Stability.ai  in Feb 2023, by Jasper in Feb 2024.\n\nCreated and led a team at  Google , doing  Arts & Cultures Experiments\n\nCreated the Google Cardboard:  ‚Ä£\n\nCo-founded   AudioGaming ,  pivot to   Novelab   sold to  Mantu .\n\nCTO of  Voxler\n\nand  more .\n\nReferences\n\nCardboard related video and articles (in French)\n\nArt selfie (with  Cyril Diagne )\n\nBlog post with Google\n\nML & Art Talks\n\nML & Art press\n\nGoogle Cardboard\n\nVirtual reality\n\nStartups\n\nANR Projects\n\nPatents\n\nProfiles Pictures\n\nProfile_1.png\n\nProfile_2.jpg\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£  (I was the first CTO)\n\n‚Ä£  (Co-founder)\n\n‚Ä£  (Co-Founder)\n\n‚Ä£  (Co-founder)\n\n‚Ä£\n\n‚Ä£\n\nVisible on  ‚Ä£\n\n7 patents related to Google Cardboard and VR\n\n1 patent related  to image analysis and processing\n\n2 patents related to voice processing"
  },
  {
    "pageId": "17d06be9-9203-801d-a349-c110b517f0ad",
    "slug": "awards",
    "title": "Awards",
    "content": "Awards\n\nDamien Henry\n\nDamien Henry‚Äôs Awards\n\nI've been lucky enough to work with world-class collaborators throughout my career. There's no mystery to it: when you work with world-class talented people, you receive world-class awards.\n\nFor Clipdrop\n\nimage.png\n\nimage.png\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\nFor the Google Cardboard\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\nFor Google Arts and Culture Experiments\n\n‚Ä£  (6 Awards)"
  },
  {
    "pageId": "f91209e2-7b34-479c-a6f9-19a89e5f3095",
    "slug": "afk",
    "title": "AFK",
    "content": "AFK\n\nDamien Henry\n\nSometimes, it‚Äôs good to be AFK\n\nWhen I'm not at my keyboard, I try to be outside. Hiking, climbing, or mountaineering.\n\nThe following pictures are from various trips over the last 10 years.\n\nIMG_20190621_152648.jpg\n\nPXL_20230709_060104367.jpg\n\nd421488f-49b0-40da-a89c-60fca75ff816.jpg\n\nIMG_2588.JPG\n\nIMG_2596.jpg\n\nIMG_2606.JPG\n\nIMG_3343.HEIC\n\nIMG_4792.HEIC\n\nIMG_6913.jpg\n\nIMG_7783.jpg\n\nIMG_7788.jpg\n\nIMG_7799.jpg\n\nIMG_9566.HEIC\n\nIMG_9571.HEIC\n\nIMG_9892.HEIC\n\nIMG_20190423_192329_263.jpg\n\nIMG_20190623_052011.jpg\n\nIMG_20191113_190237.jpg\n\nIMG_20191114_154158.jpg\n\nIMG_20191114_170316.jpg\n\nIMG_20200711_200112.jpg\n\nIMG_20200720_201032.jpg\n\nIMG_20200725_183339.jpg\n\nIMG_20200725_205822.jpg\n\nIMG_20200725_215145.jpg\n\nIMG_20200815_115919.jpg\n\nIMG-20210531-WA0039.jpg\n\nIMG-20210531-WA0077.jpg\n\nPANO_20190608_103228.vr.jpg\n\nPXL_20210710_124401577.jpg\n\nPXL_20211031_172343251.jpg\n\nPXL_20230709_081704547.jpg"
  },
  {
    "pageId": "47b0471e-5dd2-4ac6-99bf-ad66a4cc23a6",
    "slug": "machine-learning-ai",
    "title": "Machine Learning & AI",
    "content": "Machine Learning & AI\n\nDamien Henry\n\nWritings about AI\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\n‚Ä£\n\nMachine Learning projects\n\nThis is a curated list of AI-related projects I created alongside my professional work, mainly to learn through hands-on practice.\n\n2016  ML tutorials\n\nHere are some tutorials I wrote to understand ML. You can find them  on github .\n\nHow to create an RRN in pure python, to generate random English sentences, char by char?\n\nWhat does temperature mean in the context of machine learning?\n\nLearning TensorFlow fundamentals, by doing a simple linear regression.\n\nWhat is a Mixture Density Network and how to use it?\n\nFizz Buzz with TensorFlow.\n\nHow to create and teach a neural network to generate MNIST Char?\n\n2017  üî•¬†Learning a model of the world by predicting the future\n\nThis video is 100% generated by an algorithm in one shot. No edit or post-processing.\n\nI used videos recorded from trains windows, with landscapes that move from right to left and trained a Machine Learning (ML) algorithm with it.\n\nFirst, it learns how to predict the next frame of the videos, by analyzing examples. Then it produces a frame from the first picture, then another frame from the one just generated, etc. The output becomes the input of the next calculation step. So, except the first one that I chose, all the other frames were generated by the algorithm.\n\nThe results are low resolution, blurry, and not realistic most of the time. But it resonates with the feeling I have when I travel on a train. It means that the algorithm learned the patterns needed to create this feeling. Unlike classical computer-generated content, these patterns are not chosen or written by a software engineer.\nIn this video, nobody made explicit that the foreground should move faster than the background: thanks to Machine Learning, the algorithm figured that itself. The algorithm can find patterns that a software engineer may haven‚Äôt noticed and is able to reproduce them in a way that would be difficult or impossible to code.\n\nWhat you see at the beginning is what the algorithm produces after very little learning. It learns more and more during the video, that's why there are more and more realistic details. Learnings are updated every 20s.\n\nThis video was made as side project, but was also documented later there as part as the  magenta google project.\n\nIt was featured in the press manywhere, for instance  here .\n\n2017  Exploring latent space arithmetics and bias in the news, using Word2vec.\n\nML-Tutorial-Notebooks/word2vec.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/word2vec.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks\n\nThe AI Equation\n\nStatistical distribution is all you need  to understand about AIs.\n\nRethinking AI: Beyond AGI ‚Äì The Cognitive Cone\n\nTo what extent is a company an ‚ÄúAI company‚Äù?\n\nSheets x GPT = ‚ù§Ô∏è\n\n2025-02-02: Predictions about AI\n\nWriting\n\n2018  Playing with CycleGan\n\n‚Äú Entr√©e d‚Äôun train en gare de la Ciotat ‚Äù is the first movie ever recorded.\n\nI train CycleGan to predict what it should look like today.\n\nHere is the fun result:\n\n2019  üî•¬†6M+ answers to \"Le Grand D√©bat National\" organized by similarity in one DataViz.\n\nI downloaded then analyzed 6M answers to a french public debate to create a data visualization where you can see all of them by zooming into a latent space.\n\n2024 - Context window exploration\n\nContext Window Size Visualizer\n\nA simple web page (100% generated) to help humans visualize and understand different context window sizes.\n\n‚Ä£\n\nLLM Challenges\n\nAnother simple web page (100% generated) to create challenges for LLMs. Compare different LLMs and test their performance across various scenarios.\n\n‚Ä£\n\nRNN stands for \"Recurrent Neural Network\".To understand why RNN are so hot you¬† must ¬†read¬† this !\n\nThis notebook explains the¬† Minimal character-level Vanilla RNN model ¬†written by¬† Andrej Karpathy, t his code creates an RNN to generate a text, char after char, by learning char after char from a textfile.\n\nML-Tutorial-Notebooks/RNN.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/RNN.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks\n\nI love this¬† character-level Vanilla RNN ¬†code because it doesn't use any library except NumPy. All the NN magic in 112 lines of code, no need to understand any dependency. Everything is there! I'll try to explain in detail every line of it. Disclaimer: I still need to use some external links for reference.\n\nThis notebook is for real beginners who want to understand the RNN concepts by reading code.\n\nTemperature is a concept that is used when you need to generate a random number from a probability vector but wants to overemphasize samples that have the highest probability.\n\nThis notebook shows the effects in practice.\n\nML-Tutorial-Notebooks/Temperature.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/Temperature.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks\n\nML-Tutorial-Notebooks/tf-linear-regression.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/tf-linear-regression.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks\n\nML-Tutorial-Notebooks/tf-MDN.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/tf-MDN.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks\n\nThis notebook  explains the¬† code ¬†from¬† Fizz Buzz in TensorFlow ¬†blog post written by¬† Joel Grus You should read his post first!\n\nHis¬† code ¬†tries to play the Fizz Buzz game by using machine learning.\n\nML-Tutorial-Notebooks/keras_mnist_generator.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks This depot contain tutorials for real beginners who want to understand machine learning by reading some code. - ML-Tutorial-Notebooks/keras_mnist_generator.ipynb at master ¬∑ dh7/ML-Tutorial-Notebooks"
  },
  {
    "pageId": "1a7e021d-4ed2-42e1-ab76-9b9e92308bb0",
    "slug": "google-cardboard",
    "title": "Google Cardboard",
    "content": "Google Cardboard\n\nDamien Henry\n\nThe creation of the Google Cardboard\n\nimage.png\n\nOne of the most fun and impactful projects I started is the ‚ÄúCardboard‚Äù.\n\nHere are some pictures of the first Cardboard versions:\n\n2013-10-03 First iterations from home\n\n2014-03-12  First series, done at Google Arts & Culture Lab in Paris\n\n2014-06-26 All other iteration in California with Google, for Google IO\n\nGoogle Cardboard story, part 1.\n\nhttps://www.instagram.com/p/fIbe7-OYWX/\n\nUntitled\n\nUntitled\n\nUntitled\n\nhttps://www.instagram.com/p/fpGxsBuYRt\n\nUntitled\n\nhttps://www.instagram.com/p/hX_fX-OYai/\n\nUntitled\n\nOriginal drawing:  https://github.com/VR4ALL/cardboard_goggles/blob/master/goggle_test.pdf\n\nhttps://www.instagram.com/p/ldaf_dOYcF/\n\nUntitled\n\nI‚Äôll share this incredible story some day üòä"
  },
  {
    "pageId": "11706be9-9203-809d-827a-ff4650064aaa",
    "slug": "fix-typoscom",
    "title": "Fix-typos.com",
    "content": "Fix-typos.com\n\nDamien Henry\n\nFix Typos in 1 click\n\nFix typos in 1 click The best way to fix typos online, 100% free\n\nFix-typos.com  is a simple website designed to fix typos.\n\nI created it as an exercise to try out Cursor.sh. It took less than three evenings to build a functional version using Vercel, Next.js, Tailwind, Firebase, and Claude.\n\nThe entire project took about two weeks (only evenings). The most time-consuming part was refining the UI to ensure the tool is efficient and distraction-free.\n\nYou can find the full story here:\n\n10h with Cursor.sh\n\nWriting"
  },
  {
    "pageId": "4f1223a4-34c3-4a4f-86d1-37d348ae9819",
    "slug": "20-watts",
    "title": "20 Watts",
    "content": "20 Watts\n\nDamien Henry\n\nThe smart T-shirt brand\n\nTwenty-watts is a T-shirt brand dedicated for individual that value science and knowledge.\n\nTwenty watts Your brain only requires 20 watts to function. Twenty-watts is a T-shirt brand dedicated for peacefull individual that value science and knowledge.\n\nCreating T-shirts is a fun and relaxing hobby, and selling them is a great way to see the world from the other side of the internet.\n\nMy primary objective for this project was to gain hands-on experience with social media advertising.\n\nKey learnings:\n\nGood imagery is essential for selling products online.\n\nAds are expensive.\n\nCustomer acquisition cost is king.\n\nPersistence is key to building an audience.\n\nFor many businesses, marketing‚Äînot product creation‚Äîis the main challenge.\n\nFor many brands, investing in performance marketing (ads) often has a greater impact than improving their products.\n\nAs a consumer, I'd appreciate a breakdown of product costs: materials, labor, and advertising. This transparency could rebalance incentives for brands, favoring product quality."
  },
  {
    "pageId": "73cbb268-8bfb-4fc8-8cc4-5cd007f79ae2",
    "slug": "reading",
    "title": "Reading",
    "content": "Reading\n\nDamien Henry\n\nBooks summaries\n\nAbout Startups\n\n(Strategy) Playing to win\n\n(Product discovery) Discovery Discipline\n\nMonetizing Innovation\n\nContinuous API management\n\nBuilding Microservices\n\nAbout Biological & Artificial Sentience\n\nBacklog\n\nThe case against reality - Donald D. Hoffman\n\nThe fabric of reality\n\nMetaphors we live by\n\nHow to find what is not lost\n\nOther non fiction\n\nHow to Live - Derek Sivers - book summary"
  },
  {
    "pageId": "895518b5-374b-4121-aeea-4c984f5c7db2",
    "slug": "writing",
    "title": "Writing",
    "content": "Writing\n\nDamien Henry\n\nWriting is a tool for thinking that took me time to master.\n\nI struggled with writing in school‚ÄîI was really terrible at it. Over time, I've grown to enjoy the writing process much more. And AI is there to help.\n\nThese posts are mostly written on my phone in planes or trains.\n\nAI related\n\nStatistical distribution is all you need  to understand about AIs.\n\nRethinking AI: Beyond AGI ‚Äì The Cognitive Cone\n\nThe AI Equation\n\nTo what extent is a company an ‚ÄúAI company‚Äù?\n\n10h with Cursor.sh\n\n2025-02-02: Predictions about AI\n\nSheets x GPT = ‚ù§Ô∏è\n\n(WIP) AI x UX\n\n(WIP) Advices for parents regarding AI\n\nOn Twitter / X\n\nAbout Virtual Reality\n\nAbout Reality\n\nAbout the French Tech ecosystem\n\nRandom thoughts\n\nProblem space\n\nAbout Virtual Reality\n\nWhy free elections have 50/50 results?\n\nHigh Dimensional spaces\n\nMicro fictions\n\nThe naked wave\n\nDamien Henry on Twitter / X I created the Google Cardboard almost ten years ago but quit VR soon after to focus on Machine Learning.VR is based on a ridiculous misunderstanding.Let me explain why in this thread. pic.twitter.com/iFUXLT36uH‚Äî Damien Henry (@dh7net) October 3, 2023\n\nDamien Henry on Twitter / X Does an apple exist when no one watches it? Donald D. Hoffman thinks it doesn‚Äôt, and his book explains why.Here is a short summary. üßµüëá pic.twitter.com/yQTnkpw86j‚Äî Damien Henry (@dh7net) April 10, 2023"
  },
  {
    "pageId": "15c06be9-9203-80ec-a361-f4281a6e01c7",
    "slug": "machine-learning-ai/the-ai-equation",
    "title": "The AI Equation",
    "content": "The AI Equation\n\nWriting\n\nDamien Henry\n\nCreating More Value from AI Applications\n\nDamien Henry, Posted Jan 1 2025, small edit on Sep 11 2025.\n\nEdit on sep 7 2025, Edit for clarity, and updated the Tool section.\n\nHaving worked in machine learning for over 10 years, I've witnessed a dramatic acceleration in the field recently, with AI becoming an increasingly significant part of my work. Through this journey, I've gained valuable insights about creating value with AI that I'll share today.\n\nLet's start with this key insight: despite all the hype surrounding AI, \" Intelligence \" alone accomplishes nothing. Intelligence requires a physical form‚Äîwhether biological or digital‚Äîand energy to exist. It needs both input and something to act on its output. When evaluating AI products, we can break down their value creation into a simple equation. Intelligence is just one piece of this puzzle, as we'll explore.\n\nThe AI equation\n\nAI Value = User Intent * User Context * Knowledge * Intelligence * Tools * Trust\n\nAI Value:  This represents the practical benefit delivered to the user through AI technology.\n\nUser Intent:  What the user wants to achieve. AI systems don't have goals of their own. Most often, users communicate their intent through a prompt.\n\nUser Context:  Without context, it's impossible to correctly understand user intent. User context encompasses everything users know that LLMs don't‚Äîfrom personal information to project-specific details.\n\nKnowledge:  This represents the information users need but don't currently have. For critical tasks, users typically need more reliable sources than LLMs or web-based information.\n\nIntelligence:  It serves as the connector that understands intent, knowledge, and context, translating them into actionable results. Today, most AI systems use LLMs to make decisions, making them the core of AI intelligence.\n\nTools:  Tools are the pathways that transform decisions into actions. These can be API access or ecosystem integrations. MCP is trying to become the connection standard between the intelligence and the world. An LLM with tools becomes agentic.\n\nTrust:  Users must trust the UX to understand their needs and context, trust the knowledge and data sources being used, and trust the system's decision-making ability. This trust becomes particularly vital when AI operates autonomously.\n\nCreating More Value\n\nWhen creating a product based on AI, we can use this equation to increase the value we generate by acting on these levers.\n\nLet's break down all the parameters and see what we can activate.\n\nCapturing User Intent\n\nChatGPT, Claude, and other major players use chatbots as their primary interface. Chatbots are indeed an amazing way to let users express their needs, especially because they offer multi-turn interactions. If the tool doesn't understand the intent initially, users can refine their request through conversation until they feel understood. However, this system has limitations. Sometimes it's more efficient to undo an interaction and start over rather than trying to clarify a misunderstanding with the chatbot. But the biggest limitation lies in language itself.\n\nThis creates a significant opportunity for startups looking to differentiate themselves from OpenAI and similar companies. Very few tasks require purely language-based interaction. In practice, depending on your work, you need to interact with written documents, forms, code, slides, images, drawings, sketches, videos, plans, schedules, maps, and more. Currently, the only way to communicate with AI about these elements requires either converting them to text or sending screenshots.\n\nIn other words, limiting users to expressing their needs through language (or images) creates a huge bottleneck. Every startup developing a novel product should ask themselves: how can we capture our users' intent and needs at the right level of abstraction for AI to process?\n\nFor example, text editors still make users type character by character‚Äîwhich seems ridiculous in the AI era. The open question is: what novel interactions can we create to let users write without typing character by character? It's a fascinating problem that involves capturing the essence of the text to write directly from someone's brain. There's tremendous room for creativity here.\n\nRethinking AI: Beyond AGI ‚Äì The Cognitive Cone\n\nCapturing the Context\n\nimage.png\n\nMost interesting work requires successfully completing multiple complex tasks that shares the same context.\n\nThe user context is made of all the background information that shapes how AI should interpret and respond to prompts. This includes project-specific details, user preferences, historical interactions, and any constraints or requirements that should influence the work.\n\nThe challenge with capturing context is that it often exists outside of the product itself. Context is typically scattered across various platforms and mediums - it might live in Slack conversations, Google Docs, informal team discussions, email threads, or even current news events. This distributed nature of context makes it particularly challenging to capture and integrate effectively.\n\nThe key challenge for AI products is finding elegant ways to pull in this external context without creating additional friction for users.\n\nKnowledge\n\nWhile Large Language Models (LLMs) have absorbed vast amounts of knowledge from the open web during their training, this represents only a fraction of the world's valuable information. Many companies build their business models around collecting, curating, and selling specialized datasets that aren't freely available online. Additionally, LLMs tend to generate balanced, averaged responses that try to accommodate multiple viewpoints - which isn't always helpful for decision-making.\n\nFor critical tasks or precise decision-making, products need to leverage authoritative, detailed knowledge sources. This is what separates a vague, hedged response from ChatGPT from an actionable, precise answer provided by a product with access to high-quality, specialised information. The difference in value between these two approaches can be dramatic - generic knowledge versus deep, reliable expertise that enables confident action.\n\nInteligence\n\nWhat makes AI special today isn't its depth of reflection or analysis, but rather its unique capabilities: the ability to instantly process vast amounts of information (like reading an entire book in seconds), explore multiple paths in parallel, and bridge knowledge across vastly different domains (like simultaneously writing code and poetry in a language unknown to the user).\n\nLLMs aren't intelligent in the same way humans are, but they have have been trained on so many problems and solutions that they can function as an intelligent engine in many use cases.\n\nTools\n\nWhile ChatGPT feels immensely useful for many tasks,  AI's potential remains largely untapped, primarily because most products don't allow AI to take direct actions.  As mentioned earlier, few tasks require purely language-based interaction. In practice, your work likely involves interacting with various media: written documents, forms, code, slides, images, drawings, sketches, videos, plans, schedules, maps, and more.\n\nFor instance, you can ask ChatGPT to explain how to use a spreadsheet for a specific goal, but what's the advantage if Gemini can edit the spreadsheet directly? Similarly, ChatGPT can help plan your vacation, but it can't book hotels or flights for you.\n\nWe are currently in an absurd moment in time where we must translate everything for AI, get its advice, and then translate that advice back into the medium where we're actually working. ChatGPT interacts through the clipboard while users copy and paste content back and forth. This inefficient workflow makes no sense and many businesses and startups will flourish simply by streamlining these interactions.\n\nThe above paragraph was written before AI agents began leveraging tools. AI agents are LLMs that can call tools, giving the LLM some agency. The popularity of MCP demonstrated how crucial this capability is for the ecosystem.\n\nTrust\n\nThe first thing that ChatGPT and other AI tell their users is \"AI can make mistakes.\" It's a well-known fact that AI can hallucinate. What's most troubling is how quickly some answers can become incoherent. To fully tap into AI's power, we want it to be as autonomous as possible. We want AI to have the agency to solve increasingly complex problems. There's no simple solution to this challenge, so let's break it down.\n\nToday, we can see that hallucinations are becoming less frequent but haven't been eliminated. Through tools like Cursor and other coding assistants, we can observe AI's potential agency. While AI can impressively code complex UX, it requires close supervision as it can drift into nonsense. It's also highly sensitive to ambiguity‚Äîthe smallest misunderstanding can lead to catastrophic results. In this context, trust is built by letting the user validate all the critical points.\n\nAnother dimension of trust concerns the intrinsic knowledge of LLMs. Can we trust OpenAI regarding their training data? Can we use the results without risking copyright issues? Curating external knowledge can help build trust for this point on top of potentially reducing the hallucinations.\n\nThere's also another crucial point: AI is based on probability. Unlike classical code, you can't prove it will always give the right answer. It might be right 80% of the time, 99% of the time, or maybe 99.9% of the time. So the key question is: what accuracy level does your product/feature need to be viable?\n\nConclusion\n\nThe AI equation helps understand that creating value with AI involves much more than just leveraging an LLM API. By focusing on all components‚Äîintent & context capture, external knowledge curation and integration, LLMs capabilities, Tools, and trust building‚Äîwe can develop more effective AI applications.\n\nSuccess in AI product development comes from recognizing these interconnected elements and addressing them holistically. The companies that will thrive in the AI era won't be those using marginally better models, but those who excel at combining all these elements into seamless, trustworthy, user experiences."
  },
  {
    "pageId": "26c06be9-9203-80b5-9d7b-fd97766a2fa5",
    "slug": "machine-learning-ai/statistical-distribution-is-all-you-need-",
    "title": "Statistical distribution is all you need ",
    "content": "Statistical distribution is all you need  to understand about AIs.\n\nWriting\n\nDamien Henry\n\nOct 2025 ‚Äî written by human, improved by AI\n\nIntro\n\nBuilding a house on an unfinished foundation doesn't seem like a good idea, yet that's exactly what startups are doing today when they build products on top of AI systems. Indeed AI is not done yet. It's a moving target that, while bringing high-paced innovations to the table, can't be considered fully mature or stabilized yet.\n\nThriving in such an environment requires navigating ambiguity at a whole new level.\n\nUsers don't know what's possible with AI, creators don't know what users should expect, and no one fully understands what AI is capable of.\n\nBut there is a useful concept that can help:  Statistical distribution.\n\nThis post draws from my experience at Novelab, Google, ClipDrop, and Jasper, where I became accustomed to building experiences, POCs, and products on top of numerous immature technologies, including various forms of AI.\n\nUnderstanding  Statistical distribution  is key to unlocking AI's power‚Äîlet me explain why in the following post.\n\nClarification\n\nPart 1: What are distributions in the context of AI\n\nExplicit programming vs Deep Learning\n\nMost traditional algorithms are  deterministic . That‚Äôs why humanity loved computation in the first place: it guaranteed that calculations could always produce the same, correct result. Computation makes it possible to process billions of transactions per second with perfect accuracy.\n\nModern AI, based on deep learning, doesn‚Äôt work like that. Instead, its internal rules and decision-making processes are  learned from data  rather than explicitly programmed.\n\nThe main consequence is that an AI-based system can‚Äôt be  formally proven correct  the way a traditional algorithm can. At best, we can measure its performance in terms of the  percentage of correct answers  it gives under testing conditions.\n\nHow Deep Learning works.\n\nLet‚Äôs forget the details for now. What you need to know in 2025 is that  AGI is still a myth ‚Äîand the hype around it doesn‚Äôt help.\n\nAI is, at its core, an  input‚Äìoutput system .\n\nDuring training, it learns to associate outputs with inputs. If you train it on enough input/output pairs, it will usually produce the right output for a given input.\n\nBut this only works if the input is reasonably similar to what the system has seen during training. For example, if you train a system to generate images from prompts, it will only work well for the kinds of prompts it was exposed to during training, and it will generate only the kinds of images it learned to associate with them.\n\nThis core mechanism becomes surprisingly powerful when AI is combined with external tools. The ability to search, read, write, or call APIs makes AI immensely capable.  But the fundamental limitation remains: it works best when the input/output patterns were present in the training data.\n\nOf course, reality is more complex‚Äîbut the basic principle holds. In 2025, AI  interpolates ; it does not truly  extrapolate.\n\nDistribution explained with a  fruit basket.\n\nImagine you have a big fruit basket.\n\nThe following contains deliberate simplifications that might trouble purists: a model doesn't have to be perfectly accurate to be useful. What follows is sufficient for making good decisions. If you want a deeper understanding,  this video  is an excellent resource.\n\nIf it‚Äôs  full of apples and bananas , and just a few oranges, then the  distribution  of fruit is: ‚Äúmostly apples and bananas, rarely oranges.‚Äù\n\nIf you pull out a fruit at random, chances are high it‚Äôll be an apple or banana, and low it‚Äôll be an orange.\n\nNow, if I train an AI on this basket:\n\nIt will get very good at recognizing apples and bananas.\n\nIt might be able to spot oranges, but not very reliably.\n\nIf you suddenly add a pineapple (which it has never seen before), the AI won‚Äôt know what to do with it ‚Äî because pineapples weren‚Äôt part of the distribution of the training set.\n\nIn other words,  AI is only as good as the ‚Äúdistribution‚Äù of data it has learned from . A distribution simply means the patterns or categories of examples the model has been exposed to.\n\nThat's why Large Language Models have been trained on the full breadth of information available on the internet. This covers the broadest possible distribution. The training set is so large that on the surface, an LLM seems capable of novel tasks. However, the general rule still applies: if a request falls within the types of examples the AI has seen before, the results can be excellent. But if the request lies outside that range, the output quickly loses quality.\n\nFeeling the distribution\n\nimage.png https://artsexperiments.withgoogle.com/art-emotions-map/\n\nOne simple way to visualize a distribution is to create \"maps\" of the data. Several techniques exist for this‚Äîthe most efficient is to plot all the data in a high-dimensional latent space, then reduce it to 2 dimensions using UMAP.\n\nHere are some links from my time at Google.\n\nDistribution of images\n\nDistributions of concepts\n\nDistribution of color palette\n\nDistribution of emotions\n\nDistribution of body position\n\nDistribution of sentences\n\nIf you're curious, don't just watch the videos‚Äîtry the experiments yourself using the links above.\n\nPart 2: Why distributions matters for AI Products\n\nReal-World example\n\nThis story occurred in 2023 while I was working for ClipDrop (A company I cofunded, sold to stability.ai in 2024)\n\nHere's an important nuance: we're discussing distributions, not individual examples. AIs interpolate. For instance, you can generate an image of an astronaut in the jungle even if no such image exists in the dataset. This works because the dataset contains plenty of astronauts and plenty of humans in jungles‚Äîso the result isn't \"out of distribution,\" but rather sits between existing examples. A truly out-of-distribution request would be generating an animal that doesn't appear in the training set. In that case, the AI has no way to guess its appearance. AI isn't magical‚Äîit's an incredibly powerful interpolator.\n\nWe developed a mobile app that, among other features, removed backgrounds from images.\n\nOur model was initially trained on open source data, then we incorporated user data until our model became highly effective.\n\nWhen we launched a web version of ClipDrop using the same algorithm, users were dissatisfied. We discovered why: the distribution of images from mobile differed significantly from those on the web. On mobile, users typically photographed simple objects like their hands or mugs‚Äîthe easiest subjects available. On desktop, however, they uploaded images and deliberately chose complex subjects to test the system, particularly portraits with intricate hair.\n\nAfter retraining our model to handle complex hair, our users were satisfied again.\n\nWhat is a good model?\n\nThis experience with Clipdrop was a wake-up call. There's no such thing as a universally \"good model\" ‚Äì only models that perform well for specific distributions. Having the broadest possible distribution doesn't guarantee coverage of your specific needs. Furthermore, the broader the distribution, the larger the model needs to be, which increases latency and cost while potentially decreasing quality for specific targeted use cases.\n\nHere is an example about coding:\n\nimage.png\n\nHow to apply this when building a product?\n\nFrom a product perspective, distributions map directly to  use cases.  For instance at a broad level, coding is one distribution, marketing text is another, image creation yet another. Within each, there are narrower distributions: in coding, tasks like refactoring or bug fixing; in writing, tasks like blog posts versus SEO snippets.\n\nAn AI system may excel at one but underperform at another, depending entirely on whether those patterns were well represented in training.\n\nWhen designing AI products, success depends on matching the  intended use case  with the  distribution the model has mastered . Performance is strongest when requests stay close to the familiar patterns, weaker at the edges, and unreliable outside them.\n\nIn other words, product-market fit is reached when the distribution of user needs matches the distribution of problems a product can solve.\n\nThis explains why  specialized AI products ‚Äîtools designed for specific tasks like contract review or bug fixing‚Äîoften outperform general-purpose tools. By focusing and optimizing on a narrower distribution, they align much more closely with users' real needs.\n\nUsing distributions to train a model\n\nIf you are building and training models, the most important step is to  identify the distributions that matter to your users . In practice, this means understanding the exact types of tasks and inputs they will bring to the system, and ensuring your training data reflects those patterns. Aligning the training set with the user‚Äôs distribution of needs is the surest path to reliable performance.\n\nUsing distributions to choose between existing models\n\nWhen selecting between existing models, this same principle applies. First, identify  which distribution your product depends on . This clarity will help you evaluate which model will best serve your users' needs.\n\nUsing distribution for prompting\n\nWhen prompting, ensure everything in your prompt matches the expected distribution. If you want a professional answer, make your prompt professional. If you want a friendly answer, make your prompt friendly. If you want the model to focus, don't include distractions in the prompt. Strangely, anthropomorphizing the model works‚Äîbut the reason is fundamentally about input and output distribution. For example, adding \"BTW cats are always sleeping\" at the end of a mathematical question has been shown to significantly decrease performance. This isn't because the model gets confused by such a simple addition, but because there are very few mathematical problems about sleeping cats in the training data. We're essentially asking the model to work outside its main distribution. A good practice is to ask the LLM to rewrite your prompt in its own words. This way, the LLM will reformulate the request within its distribution, and you can verify that it understands your intention.\n\nPart 3: Comunication & Distribution\n\nTests sets to the rescue!\n\nAI models can \"memorize\" training examples instead of truly learning. It's like teaching a child  2+2=4  and then testing them with  2+3 . If they succeed, they've learned the rule, not just memorized the answer.\n\nTo check for true learning, researchers use a  test set : data from the same distribution as training, but with different examples. The larger and more representative the test set, the more accurate the evaluation.\n\nThis is how AI creators measure model quality ‚Äî and it's how everyone should measure quality too! Even when you test a model randomly, your test is effectively a test set with its own distribution. This explains why the \"vibe check\" of a model can feel different from benchmark results: often, the benchmark distribution doesn't match the user's real-world usage distribution.\n\nIf you need to create a model: create the test-set first. This helps you understand the problem and confirm with all parties that the model will solve the right problem. It defines the needed distribution for the training set and makes its creation faster and cheaper.\n\nIf you're creating a product that needs AI: create the test-set first. This dramatically improves your evaluation of model candidates: a handful of tests is never enough; proper evaluation requires testing against a full distribution of inputs.\n\nConclusion\n\nDistribution is a key concept to understand how AI behave and how to create value with it.\n\nTest-sets should always be the first thing to consider when you are in charge of an AI project. They are the clearest way to communicate intent unambiguously across teams.\n\nBTW, In classical organizations, it's not clear who should be responsible for the distribution of the test-set. Depending on the task, it could be PMs, researchers, engineers, or designers. I have no doubt that as AI-first companies develop, they will need new roles‚Äîincluding one dedicated to managing test sets and ensuring their distribution matches company objectives.\n\nHere's the key activable insight from this post: use test-sets as specification and communication tools. In other words: whatever you want to do with AI, create the test set first."
  },
  {
    "pageId": "15c06be9-9203-8049-b597-cb72f386f20a",
    "slug": "machine-learning-ai/rethinking-ai-beyond-agi-the-cognitive-cone",
    "title": "Rethinking AI: Beyond AGI ‚Äì The Cognitive Cone",
    "content": "Rethinking AI: Beyond AGI ‚Äì The Cognitive Cone\n\nWriting\n\nDamien Henry\n\nExpanding our understanding of AI progress through Michael Levin's cognitive cone framework.\n\nDec 14, 2024 ‚Äì  This text is mostly generated under tight supervision.\n\nOct 7, 2025 - Removed distracting subtitles, and the concept of emergence.\n\nArtificial General Intelligence (AGI) is a vague concept , often debated over what truly qualifies as \"general\" intelligence. Some might argue that systems like ChatGPT have achieved AGI because they handle many tasks. However, these systems, like all intelligent ones, have limitations and aren't universally \"clever.\" In other words, AGI is a poor metric for measuring progress and therefore cannot effectively guide development.\n\nIn his 2019 paper, \" The Computational Boundary of a 'Self': Developmental Bioelectricity Drives Multicellularity and Scale-Free Cognition, \" Levin articulates this idea:\n\n\"Any Self is demarcated by a computational surface ‚Äì the spatio-temporal boundary of events that it can measure, model, and try to affect. This surface sets a functional boundary‚Äîa cognitive 'light cone' which defines the scale and limits of its cognition.\"\n\nimage.png\n\nMichael Levin‚Äôs concept of the  cognitive cone , as visualized in the diagram, provides a powerful framework for understanding and guiding AI progress. It reframes intelligence not as a binary achievement but as a continuum defined by the breadth and depth of a system's perceptive and actionable range. Here‚Äôs how this perspective can shape how we think about AI development.\n\nApplication regarding AI development\n\nAI progress should be measured by how far its cognitive cone extends‚Äîits ability to perceive, process, and act across broader spatial and temporal scales. Intelligence grows as systems integrate predictive modeling, memory, and goal adaptability, enabling them to address challenges like global systems coordination or long-term planning. While early systems had narrow, task-specific cones, modern AI demonstrates broader adaptability but still lacks strategic foresight.\n\nLevin‚Äôs concept of compound intelligence suggests that interconnected AI agents can collaborate to form larger-scale cognition. For instance, networks of autonomous systems could collectively address challenges beyond the scope of individual agents.\n\nAdvanced AI systems should be capable of adjusting the scope of their cognitive cone dynamically in response to changing goals, environments, or contexts. This adaptability allows the system to expand its focus to address long-term, large-scale challenges or narrow it for immediate, localized tasks. I don't think current AI systems have shown this trait yet.\n\nAI need not mimic human cognition to be advanced. In fact, AI already surpassed some human limitations since the calculator. It could surpass more human limitations by developing cognitive cones capable of handling planetary-scale data or operating in domains inaccessible to humans.\n\nApplication regarding AI product\n\nIntelligence doesn‚Äôt exist in a vacuum‚Äîit depends on what a system can perceive, understand, and do. Evaluating how \"intelligent\" a system is without considering its ability to access knowledge or take meaningful actions misses the point.\n\nIf you‚Äôre building something based on AI, think about the cognitive cone of your system. What can it perceive, how aware of the past is it? How much of the future can it predict? How far does its influence extend?\n\nFocus on expanding it‚Äîwhether by increasing its access to data, enabling it to operate in new domains, or empowering it to act meaningfully on its insights. A well-designed cognitive cone isn't just about intelligence; it's about creating systems that deliver real value. While this may sound like a clich√©, it becomes more meaningful when we consider the simplest definition of intelligence: the ability to achieve goals."
  },
  {
    "pageId": "7a9f4879-1b5f-4126-8dcc-5b46e32b4f47",
    "slug": "machine-learning-ai/to-what-extent-is-a-company-an-ai-company",
    "title": "To what extent is a company an ‚ÄúAI company‚Äù?",
    "content": "To what extent is a company an ‚ÄúAI company‚Äù?\n\nWriting\n\nDamien Henry\n\nDamien Henry, Posted Sep 5 2024\n\nThis post suggest a classification based on 10 levels.\n\nLevel 1: The company doesn't use AI.\n\n‚Üí Their competitors, suppliers are already using AI and it‚Äôs already changing it's position in the ecosystem.\n\n‚Üí Some employees are using Claude, ChatGTP, or other tools for work without telling their boss.\n\n‚Üí In fact, all the tools we are using use AI under the hood. Your inbox, your camera, your social feeds depend on learning algorithms.\n\nIn other words, it's impossible to run a business strictly without AI, even if someone wanted to.\n\nLevel 2: The company uses AI officially.\n\n‚Üí The company subscribes to a couple of SaaS.\n\n‚Üí For instance, it may use @clipdropapp for image editing or @heyjasperai for text generation.\n\n‚Üí This may company encourages employees to use Claude or ChatGPT for work.\n\nMost companies are at level 2 today.\n\nLevel 3: The  compagny implements AI workflows\n\n‚Üí This company restructures its workflows around AI to maximize automation.\n\nMost companies are becoming level 3 while you are reading this thread. They are restructuring the way they are organized to maximize positive AI impact.\n\nLevel 4: The company is an AI-first company\n\n‚Üí It is a SaaS, and their product wouldn‚Äôt exist without AI.\n\n‚Üí It is likely doing generative AI, but it can be something else.\n\n‚Üí It has a good understanding of the market and injects some \"know-how\" through prompt engineering to differentiate themselves from vanilla AI providers like OpenAI.\n\nHundreds of AI-first startups are founded every day; there is tough competition for Level 4 companies.\n\nLevel 5: The compagny owns proprietary data\n\n‚Üí The company found a way to capture important business data and leverage them through AI.\n\n‚Üí It can offer a differentiated service than most competitors, especially vanilla AI providers like OpenAI won't be able to offer.\n\nHaving exclusive data can be a moat.\n\nLevel 6: The company AI is learning by itself!\n\nI learned this concept from @ericschmidt during a chat when I was working at @google. He was an active and early AI evangelist. For him, this was ‚Äúa new moat‚Äù that can make a small startup beat a big company.\n\n‚Üí The idea is that you can learn things from your users. For instance, you can use thumbs up/thumbs down feedback to retrain your models.\n\n‚Üí The more users you have, the better your model becomes. The better your model becomes, the more users you'll have.\n\n‚Üí To operate at this level, you need to train or at least fine-tune your own models.\n\nOpenAI is famous for using RLHF, and that's a clear advantage they have today: they have more users.\n\nHaving a product able to learn by itself was the initial meaning of ‚ÄúAI first company‚Äù in the pre-OpenAI days.\n\nThis is what @cyrildiagne, @jblanchefr, and myself had in mind when we created @clipdropapp.\n\nClipdrop is level 6.\n\nLevel 7: The company owns its AI infrastructure.\n\n‚Üí Training models were too expensive and sensitive. To stay ahead, the company owns data centers or enters into multiple-year partnerships with another player that owns some.\n\n‚Üí OpenAI is almost at level 7 with it's relation with Microsoft.\n\n‚Üí Stability reached level 7 for a moment with a costly partnership with AWS. It led to a phenomenal impact (stable diffusion) but dried up their runway.\n\nThe GAFAM are all at level 7.\n\nLevel 8: The company owns its AI hardware.\n\n‚Üí GPUs are too expensive and prevent scale. The company didn‚Äôt want to be too dependent on a single provider, @nvidia.\n\n‚Üí Level 8 companies are creating their own hardware and own the full stack.\n\n@google has been operating at level 8 since 2015 with TensorFlow and the TPU.\n\n@meta is also operating at level 8 and introduced its first-generation chip, called the MTIA last year.\n\n@tesla is trying to reach level 8 and actively developing its own custom AI chips, primarily for its \"Dojo\" supercomputer.\n\nLevel 9: The company AI is self-sufficient.\n\n‚Üí Energy became the main cost of operation. The compagny needed to control electricity costs and start investing in electrical plants.\n\nNo company has reached level 9 yet, but there were rumors about Google wanting to invest in nuclear plants.\n\nThis shouldn't be a surprise: all huge businesses consume tons of energy and want to reduce their bills.\n\nLevel 10: The AI compagny rules\n\n‚Üí The main limitation of applying AI everywhere was regulations.\n\n‚Üí Investing massively in lobbying was not enought.\n\n‚Üí Datacenter are getting attacked by ungratefull humans despite autonomous drone swarn to defend them.\n\nOnly solution: buying Iceland  (or conquer it).\n\nThere are tons of free energy there, and datacenter are easy to cool.\n\nCreate your own state, define your own rules.\n\nOwn satelites for conectivity, they can‚Äôt be shut down.\n\nOnly @elonmusk is on a good trajectory to reach level 10 for now.\n\nConclusion\n\nThis last level is half a joke, half a reminder that these scales don't mean that every company needs to reach level 10 to be successful.\n\nI believe every company should reach Level 3, and AI-first companies should reach Level 6."
  },
  {
    "pageId": "1e906be9-9203-80f0-9bad-c91a1a1ca711",
    "slug": "machine-learning-ai/sheets-x-gpt-",
    "title": "Sheets x GPT = ‚ù§Ô∏è",
    "content": "Sheets x GPT = ‚ù§Ô∏è\n\nWriting\n\nDamien Henry\n\n(Written on May 4 2025)\n\nI've been a fan of spreadsheets for 30 years now. I'm still fascinated by their simple concept: a cell formula can use another cell's content as input. And yet, the diversity of things we can achieve with spreadsheets is astonishing. They're Turing complete, after all.\n\nWhat if we could use a GPT model inside a cell formula?\n\nOf course, this opens up a world of new possibilities. Strangely, this potential remains mostly untapped for now.\n\nI decided to explore this as a small Sunday project. As a toy project, I created a Google spreadsheet that connects to the OpenAI API through a simple Google Apps Script.\n\nimage.png\n\nI was shocked by how simple it was to implement and how powerful the results turned out to be.\n\nUnlike most spreadsheets that perform calculations, this one writes letters.\n\nimage.png\n\nSince it's spreadsheet-based, it's extremely easy to configure or transform into something else. Here's a sneak peek at how it works:\n\nimage.png\n\nimage.png\n\nYes, it's that simple. The GPT function only needs two inputs: a system prompt and the data it should process.\n\nHere is the link if you want to try it by yourself:   Sheet x GPT = ‚ù§Ô∏è"
  },
  {
    "pageId": "12106be9-9203-8083-a07c-e9be709c3102",
    "slug": "machine-learning-ai/2025-02-02-predictions-about-ai",
    "title": "2025-02-02: Predictions about AI",
    "content": "2025-02-02: Predictions about AI\n\nWriting\n\nDamien Henry\n\nPredictions for 2025, 2030 and 2035\n\nPredictions are hard, but they are necessary to check the quality of our mental models. I‚Äôll check them again in 1 year.\n\n2025:\n\nThe agency of AI agents will increase drastically.\n\nKids who are motivated to learn will see their capabilities multiply tenfold.\n\nChatting with AI will become mainstream.\n\nThe concept of dev stack will embrace AI.\n\n10x software engineers will become 100x software engineers. The market value of ‚Äúnot great‚Äù developers will decrease.\n\nAI-first Development Teams Will Emerge.\n\nUsing the right tech stack will become even more critical.\n\n\"One-person SaaS companies\" will be a target segment.\n\n30% of developers will spend more time chatting with AI than with humans.\n\nRemote workers will speak to their laptops.\n\nThe web will start being shaped for LLMs.\n\nAPI-first companies will grow faster than others.\n\nA web renaissance for micro websites.\n\nLoRa will continue to be a pillar of modern Deep Learning Architecture.\n\n2030:\n\nEducation has embraced AI.\n\n80% of knowledge worker will spend more time chating with an AI than with humans during their working day.\n\nAutomation thru AI will be mainstream.\n\nKnowledge management will become a central concept.\n\nAll large enterprises will have a Head of AI.\n\nMost of enterprises are restructuring their dev team around AI.\n\nOne-person SaaS companies will become mainstream, with several reaching unicorn status.\n\nAt least one country (or US state) will create a special legal status for \"AI Agents.\"\n\n2035:\n\nThe world is still the same.\n\nThey will have access to more tools and APIs.\n\n\"Test time\" compute (or \"reasoning\") will evolve to search solution spaces more effectively. AI systems will test multiple ideas in parallel, advancing only the successful ones until finding a solution.\n\nThis approach will become mainstream in 2025, providing agents with significantly enhanced capabilities.\n\nThis approach will work using smaller and faster LLMs, allowing them to explore multiple solutions in parallel more quickly.\n\nThanks to AI, almost every child has access to the most patient and knowledgeable teacher humanity has ever had.\n\nMobile searches on Google will almost completely disappear.\n\nPeople will use mobile apps less frequently.\n\nThe company with the best voice assistant will dominate the mobile market.\n\nThe usual stack was mostly based on some backend and frontend technologies.\n\nAI will be mentioned in most dev stacks, explicitly listing tools used for AI inference, RAG (Retrieval-Augmented Generation), prompt monitoring, prompt engineering, and templating.\n\nThe productivity gap between average and exceptional engineers will widen dramatically. Poor developers will produce code equivalent to that of someone with no qualifications.\n\nAn AI-first development team structures its entire workflow around AI tools and capabilities.\n\nThese teams will hire differently, prioritizing developers who demonstrate deep knowledge of AI tools and their effective use.\n\nThey will operate with remarkable efficiency‚Äîa team of 3 achieving what traditionally requires 20 people.\n\nThe core will consist of senior engineers with strong pre-AI experience who understand fundamentals, project organization, various tech stacks in detail, and software architecture.\n\nWith AI tools, choosing the right stack will create an even bigger competitive advantage.\n\nTeams using the optimal stack will move 10 times faster than those using suboptimal technologies.\n\nThe most innovative brands like Vercel will take this segment seriously and integrate it into their strategy.\n\nWhy ask your boss or colleague when an AI can answer you?\n\nWe'll see a surge in remote workers using voice input. Having out-loud conversations with LLMs during work will become normal. In this setting, most writing will be done by voice.\n\nThe same way Google was shaping the web indirecly by pushing every business to create SEO content, the new coming web will be shaped by the llms reading the content. They will need specific content created for them. This as started today.\n\n‚Ä£\n\nIn 2025 website owner will start design their website for LLMs, not only for humans.\n\nThanks to AI coding tools like Cursor, writing code has become much easier. As LLMs needs tools, New developers will increasingly rely on simple APIs to build most of their applications.\n\nAll websites look nearly identical in 2024. With AI-powered coding tools, it becomes incredibly easy for creative individuals to build micro-websites that truly stand out.\n\nI'm betting we'll see more and more websites like this one emerge everywhere.\n\nhttps://kprize.ai/\n\nLoRa will remain the de facto method for lightweight fine-tuning and task adaptation.\n\nIt is possible that LoRa will become a central component for agents learning new tasks.\n\nEvery education system is now structured around AI.\n\nThey have found clear answers about when to introduce it, when to authorize it, and when to forbid it.\n\nWhy ask your boss or colleague when an AI can answer you?\n\nAlmost everyone will automate most of the boring things they do digitaly.\n\nFor the industry, automation will be the key for efficiency. Lots of roles will be created around AI automation. When you apply for a job in 2030, there's a good chance you'll be asked during the interview how you automated your job search process.\n\nKnowledge management will become one of the key roles in every company. The unique knowledge that companies possess will serve as their primary competitive advantage.\n\nTheir role will be to identify automation opportunities across the organization.\n\nThey will collaborate with HR to manage large-scale organizational restructuring.\n\nThey will help strengthen knowledge management practices.\n\nLean is the keyword.\n\nSenior dev who embraced AI are in demand like never before.\n\nThis prediction isn't original‚ÄîI'm simply endorsing it.\n\nWhile resembling AI citizenship, this will primarily serve as a loophole for enterprises to avoid liability for damages caused by their AI agents while retaining the profits these agents generate.\n\nAI will unlock countless use cases that will transform how we work and interact with each other.\n\nHowever, AI's current impact won't change society as dramatically as previous technological revolutions. Let's look at the big picture:\n\nThe mastery of agriculture led to the creation of villages and towns.\n\nThe tractor freed 95% of the population to pursue jobs beyond harvesting crops and tending to livestock.\n\nComputing and the internet enabled operations at scale, making possible today's global supply chain.\n\nThe most dramatic changes are behind us. In 10 years, even if some work roles disappear and others emerge, it won't fundamentally change life in modern countries when viewed from a macro perspective.\n\nThe essentials‚Äîhow we're born, eat, travel, love, work (in front of a computer for many), and die‚Äîwill remain largely unchanged.\n\nWhile AI will accelerate the concentration of power, it will also enable counterbalancing forces to emerge. The implications of this power dynamic, however, are beyond the scope of these predictions."
  },
  {
    "pageId": "11806be9-9203-80a7-90e4-cd2b2bd0eb91",
    "slug": "google-cardboard/google-cardboard-story-part-1",
    "title": "Google Cardboard story, part 1.",
    "content": "Google Cardboard story, part 1.\n\nGoogle Cardboard\n\nDamien Henry\n\nDid you rememeber when Google annouced a \"VR headset made out of cardboard\" during Google IO?\n\nDid you ever ask yourself WAIT, BUT WHY?\n\nLet me share how it started. Here's a story that started over 10 years ago. üëá\n\nBack then, I was the Co-founder & CTO of AudioGaming, doing audio synthesis and trying to make a living in the audio industry.\n\nSpoiler: it wasn‚Äôt easy.\n\nIt's sad to say, but even though audio conveys most of the emotion, it only gets about 10% of a project's budget.\n\nWhile generating audio in realtime offers tons of creative possibility, we discovered it‚Äôs tough to make money unless you're in music or podcasts.\n\nFun fact: our tools were used for the wind sounds in \"Django Unchained\"!\n\nSo, I bought an Oculus Rift, at first to see if there was an application for 360 audio.\n\nWhile playing with it, I realized it was just 2 lenses in front of a screen.\n\nThat was my Eureka Moment. üí°\n\nSo, I held two lenses with my hands in front of my phone and saw a stereoscopic effect.\n\nSimple, but it worked!\n\nObviously, holding a phone and 2 lenses simultaneously is not very convenient!\n\nThat's how I started putting together a rough prototype using cardboard.\n\nIt wasn‚Äôt pretty, but it held the lenses in place and worked surprisingly well.\n\nEvery test brought new surprises: \"Wow, this actually works!\".\n\nSo I decided to share my findings with David Coz @dav_cz, a Google engineer, over demos in the company canteen.\n\nAfter showing an Oculus demo, I immediately followed up with my \"2 lenses in front of a phone\" trick.\n\nI wanted to develop this idea and asked if he'd handle the software. He saw the potential right away and jumped on board.\n\nTogether, we blended hardware and software to push this idea forward.\n\nOur vision was to make 3D plan so that everyone can 3D print an headset.\n\nBut cardboard prototypes allowed us to iterate quickly.\n\nWe blocked external light, improved durability, and made the VR experience more immersive with each version.\n\nBut then there was this second Eureka moment. üí°\n\nThis headset was just  perfect  ü§©\n\nBecause its USP was huge:\n\nüí∞ Affordable: starting at just a few euros, it makes VR accessible to everyone without breaking the bank.\n\n‚úÖ Easy to use: Just pop your smartphone in and you're good to go‚Äîno complicated setup required.\n\nüé® Customizable: Brands can print their logos and designs, creating a memorable marketing tool.\n\nü§ù Shareable: No straps, so you can quickly pass it around for easy, mess-free VR experiences.\n\nBut most importantly a VR headset in cardboard is a good story.\n\nIt made people curious.\n\nIt underpromized and over delivered.\n\nThe perfect combo for virality.\n\nWith access to Google‚Äôs laser-cutting tools, our little side project quickly became an official Google project.\n\nIn June 2014, we presented Google Cardboard at Google I/O. We made it open-source, and it had an immediate impact.\n\nBrands jumped on the Cardboard train to offer unique and impactful immersive experiences.\n\n25 million Cardboard app downloads later, the hype just kept growing.\n\nThe @nytimes saw the potential and distributed 1 million Cardboards to subscribers for a VR documentary on refugees. It took the print experience to a whole new level.\n\nCompanies like @Lexus got creative, offering immersive VR experiences with their packaging. It was a brilliant way to merge product marketing with cutting-edge tech.\n\nhttps://www.youtube.com/watch?v=KSdxHy8z8zo\n\n@CocaCola also jumped on board, using their packaging to provide ready-to-use VR viewers. They turned everyday products into immersive experiences.\n\nhttps://www.youtube.com/watch?v=eamKy74n-vM\n\nI was impacted so much by this project.\n\nAfter leaving my startup, I spent 6-7 years at Google, flying back and forth to California, working in their offices, and visiting the Cardboard factory.\n\nDuring that time, I also put together an awesome AI and imaging team.\n\nMentioning Ads, the cardboard wins a Lions awards at cannes.\nIt also wins a pretigious design price: the red dot awards\n\nHonestly, there's a clear \"before and after\" in my career because of Google Cardboard.\n\nBut the bigger picture is its massive global impact:\n\nüëâ it created jobs, spawned between 10 and 100 companies, and almost every ad agency pitched projects based on Cardboard.\n\nBTW I didn't mention here what happened between the prototype and Google IO.\n\nIt was intense and fun, full of good memories, and great people.\nI may share this one day!"
  },
  {
    "pageId": "11106be9-9203-80f7-a2a6-df50ca517551",
    "slug": "fix-typoscom/10h-with-cursorsh",
    "title": "10h with Cursor.sh",
    "content": "10h with Cursor.sh\n\nWriting\n\nDamien Henry\n\nA story about AI tools, and how they will change the world.\n\nSep 30 - 2024\n\nA good friend recommended me to try  Cursor.sh , so I did.\n\nI was not ready for what happened next.\n\nIt all began with a simple idea I'd been pondering for a while. Whenever I needed to check if a text was correct, I had to go through a cumbersome process: find my ChatGPT tab, log in if disconnected, start a new chat, type \"fix typo:\", paste my text to fix, and then copy the corrected text back. It was far from efficient.\n\nI knew I could create a simple website using OpenAI APIs that would accomplish the same task without needing to write \"fix typo:\" every time‚Äîa straightforward hack. Of course, I never found time to start this pet project. That is, until I decided to give  Cursor.sh  a try.\n\nCursor.sh  is another IDE, but it's a fork of Visual Studio, which is (almost) everyone's favorite. Visual Studio best extension is GitHub Copilot, a tool that autocompletes the code you're writing.\n\nCopilot is so impressively good that it feels like it's reading your mind. It accurately predicts the next function you're going to write. With just a press of the tab key, it writes it for you.\n\nThere are also ChatGPT and Claude, both excellent at writing code. However, you have to copy and paste their output into your editor.\n\nBut  Cursor.sh  takes it to another level. It optimizes the integration of Large Language Models (LLMs) even further. The LLMs have access to more context, like your full codebase or error messages if your code crashes. You can ask  Cursor.sh  to do complex tasks like \"Move the business logic of this function to the backend,\" and it will suggest modifications across multiple files for you to review before accepting them.\n\nThe point isn't that  Cursor.sh 's AI is perfect‚Äîit's not. Mistakes happen often. The key is that the AI knows enough to get you started. You receive your first reward faster, and it assists you at every step. Rewards continue to come as you progress. This reduces frustration because you're never stuck alone. You can always ask the AI for help or explanations about what's happening, what's expected, and how the code works. Every AI failure becomes a learning opportunity. It elevates \"learning by doing\" to a new level. With will, the rest follows. It's never been easier.\n\nHere is the result of this experiment:  fix-typos.com\n\nThe AI generated 95% of the code.\n\nPolishing the UI consumed 80% of the development time.\n\nBut most importantly, I've never felt more empowered.\n\nSo here are multiple predictions based on what I learn last week.\n\nIn 5 years, if you ask someone on the street about their AI \"Aha\" moment, it won't be ChatGPT. It will be tools with a narrower scope that empower them in a much deeper way. ChatGPT giving better answers than Google is nice, but when you suddenly feel you can do 10 times more of what you love, it's something else entirely.\n\nThe tech industry will be the sector most disrupted by AI, by far.\n\nSoftware engineering schools will have to reinvent themselves. Learning by doing will become the norm.\n\nA new generation of bootstrapped startups will rise, with co-founders no longer hiring full-time employees.\n\nThe efficiency gap between good and bad software engineers will widen dramatically, not narrow.\n\nUX will become the main differentiator for many products."
  },
  {
    "pageId": "a1bb6de5-9356-4c47-998b-f353b1a10709",
    "slug": "reading/strategy-playing-to-win",
    "title": "(Strategy) Playing to win",
    "content": "(Strategy) Playing to win\n\nReading\n\nDamien Henry\n\nUntitled\n\nThe 5 points to create a strategy\n\nnse-5288449165838674392-252462746.jpg\n\nThe goal is to find a strategy that aligns the 5 points.\n\nWhat is your winning aspiration?\n\nWhere will you play?\n\nHow will you win?\n\nWhat capabilities must be in place to win?\n\nWhat management systems are required?\n\nPlace the consumer in the center. It is the most important thing.\n\nnse-2672909149935572995-740006245.jpg\n\nCommunication: Simplicity and clarity\n\nnse-6872113702255157169-2037979504.jpg\n\nDecide the purpose of the enterprise; Guiding aspirations.\n\nStart with the consumer and not with the product.\n\nNeed to be inspiring for customers and employees.\n\nnse-8736798518489828331-582728714.jpg\n\nFind the right playing field.\n\nWhere to compete? Define Geographic, product range, consumer segment, channels\n\nThere is no point in trying to catch all segments.\n\nFind a segment that is aligned with company's strength\n\nnse-3842099991649797619-1839803899.jpg\n\nnse-4079266786778768096-168514257.jpg\n\nUnique value proposition\n\nCompetitive advantage\n\nnse-1093680457833189213-198109554.jpg\n\nIs the set of capabilities that must be in place to win realistic?\n\nWhat is needed to reach the capabilities level required.\n\nDo play your strength.\n\nAre capabilities unique? D√©fendable in the face of competition?\n\nnse-2215791420745145674-77472995.jpg\n\nClarity and simplicity in communications\n\nMeasure how the strategy performs.\n\nnse-2228402497477875029-144638507.jpg"
  },
  {
    "pageId": "a794aa48-a644-4333-b196-b33e0fcb3edf",
    "slug": "reading/product-discovery-discovery-discipline",
    "title": "(Product discovery) Discovery Discipline",
    "content": "(Product discovery) Discovery Discipline\n\nReading\n\nDamien Henry\n\nnse-1186892848465922639-1600829472.jpg\n\nThe book is about product discovery that is usually split into 2 phases:\n\nProblem discovery & solution discovery.\n\nnse-7838392727833134188-1129986398.jpg\n\nThe book present a more detailed approach named FOCUSED.\n\nThis framework is useful at the feature level.\n\nIt have 7 parts. Each part requires answers to several questions.\n\nFrame\n\nSucess Criteria\n\nDamage control\n\nTimebox\n\nObserve\n\nI am ___\n\nand when I ___\n\nWhat matters the most to me is ___\n\nBut ___\n\nSo I have to ___\n\nClaim\n\nLaunch tweet\n\nUnfold\n\nList 5 touch points\n\nSteal\n\nList 5 gold nuggets\n\nExecute\n\nCreate a prototype\n\nList the hypothesis we want to test.\n\nSimplify\n\nDecide\n\nGo/No go\n\nDefine the metrics\n\nDefine the goal\n\nlook at the status today and variance\n\nWhat acceptable compromise needs to be done?\n\nWhat is the appetite for this?\n\nIf the duration of the project is too long, the ROI goes down, and ruins the purpose of the project.\n\nDefining the timebox early is the most useful constraint. Should we look for a scrappy solution or solving the problem more and will guide if we need a scrappy solution or a full featured one. Are we looking for a small incremental improvement, or to a new solution?\n\nDefine the exact customer segment\n\nDefine what the user wants to achieve\n\nDefine the exact need\n\nDefine the exact pain point\n\nDefine what the user has to do instead of using your solution.\n\nSo you have a baseline to compare the new solution to the situation today\n\nWrite the launch tweet.\n\nIs it easy to communicate the value to users?\n\nWhere the user will discover the new features? emailing? in a menu? in a tutorial?\n\nWhich screens are impacted?\n\nA gold nugget is a best-in-class solution implemented by someone else.\n\nAdd 5 screenshots as a source of inspiration\n\nInteractive prototype in Figma?\n\nEx.: is the feature discoverable?\n\nEx.: will the user save time?\n\nWhat to hide?\n\nAre things well ordered?\n\nWhat can we remove?\n\nWhat should we make uniform?\n\nWhat should we reduce?\n\nDo some user ITW and check that the suggested solution works and solves the identified pain point."
  },
  {
    "pageId": "e23d62d4-6d84-4167-9317-2c40ac3ad778",
    "slug": "reading/monetizing-innovation",
    "title": "Monetizing Innovation",
    "content": "Monetizing Innovation\n\nReading\n\nDamien Henry\n\nPXL_20210901_200835686.jpg\n\nTl;dr:\n\n4 types of failures\n\nnse-6147695272260388082-1074391880.jpg\n\n5 myths\n\nIf you build a great product, customer will pay a fair value for it\n\nThe new product or service must be controlled entierely by the innovation team working in isolation\n\nHigh failure rate of innovation is normal and is even necessary\n\nCustomer must experience a new product before they can say how much they'll pay for it.\n\nUntil a business knows precisely what's it's building, it cannot possibly asses what it is worth.\n\n9 rules for successful monetization\n\nHave the \"Willingness to pay\" talk early\n\nDon't default to a One Size Fits All Solution\n\nConfiguration and bundling is more science than art\n\nGo beyond the Price point (how you charge is more important than what you charge)\n\nMarket share or Premium Branding?\n\nFrom Hoping to knowing\n\nThe Innovation wont speak for itself\n\nUse behavioral Pricing tactics to Persuade and sell\n\nMaintain your price integrity\n\nScreenshots\n\nPXL_20210901_203147554.jpg\n\nMonetizing Innovation: How Smart Companies Design the Product Around the Price Not√© /5. Retrouvez Monetizing Innovation: How Smart Companies Design the Product Around the Price et des millions de livres en stock sur Amazon.fr. Achetez neuf ou d'occasion\n\nFind the Willingness to pay (WTP) and segment your users before everything else.\n\nIt will tell you if you have the opportunity to monetize your product, or not\n\nIt will help you prioritize features and dsign the product with the right set of features\n\nit helps to avoid the 4 types of faillures\n\nSegmentation should break the market down into a few diffrent gruops on witch you can act differently\n\nThere is no point in segmenting and then acting the same with the entire market\n\nDescribe your segments so you can address them\n\nPrinciple 1\n\nPrinciple 2\n\nInsights, tips and tricks\n\n5 models\n\nHow to choose\n\nSet clear goals\n\nPick the right type of Pricing strategy\n\nDevelop price setting principles\n\nDevelop principle for reaction\n\nBuild a living business case document with WTP, etc..\n\nCrystal clear benefit statements ; not feature descriptions\n\nMake benefit statement segment specific\n\nmeasure the impact and refine your value message\n\nCompromise effect: make decision easier for people who can't choose\n\nAnchoring tactics: set the context for value\n\nUse the price to signal quality\n\nRazor/Razor blades (big bias for cheap initial price even if recuring price is  higher.\n\nPennies a day pricing (instead of showing the price per year)\n\nPsychological price thresholds\n\nDon't guess: put behavioral tactics to the test\n\nbe patient\n\ntrack\n\ndo deals deconstructions regularly (why you win or why you loose)\n\nCame with at least 3 nonpricing actions before approving a price decrease\n\nBefore reacting on price, war-game your competitions counterreaction\n\nunusually high sales is also a problem: product too cheap?\n\nPrice wars, the only winning move is not to play\n\n\"Leaders\" features, every customer wants them.\n\n\"Killer\" features: are valued by less than 20% and are not valued at all by more than 20%. Killers can kill a deal if customer who don't value them are forced to buy them in a bundle.\n\n\"Filler\" are nice to have.\n\nGood, Better and Best options\n\nNo more than 25% should choose the good, 70% should choose the Better or Best.\n\nCan be more than 3 classes if each configuration match a segment\n\nAlign with segment\n\nD'ont make it over nine benefit or for products\n\nMake sure your customer and you both benefit\n\nD'ont give too much away in your entry-level product\n\nHard bundeling will not always work. Allowing to buy the part separately can be good. Hard bundeling works when you have market power and are the dominant player. In other cases, you should go with a mixed bundeling approach\n\nIndividual prices need to be higher with mixed bundling\n\nDon't forget bundle price communication\n\nBundle with integration value that 1+1 = 3\n\nDon't bundle for the sake of bundling\n\nExploit inverse correlation. Can help to sell the same thing to 2 groups\n\nThe subscription model\n\nDynamic pricing\n\nAuctions\n\nPay as you go\n\nFreemium (land and expand)\n\nHow likely are your customers to accept the model?\n\nHow will future developments impact the model?\n\nDoes your model fit the stage of your compagny?\n\nWhat your cometitor are doing?  Is there a way to set yourself apart?\n\nHow difficult is the monetiation model to implement?\n\nMaximization\n\nPenetration\n\nSkimming\n\nMonetisation model\n\nPrice differentiation or not? (per region?) what is the maximum spread?\n\nPrice floors, what is the price you'll never go below?\n\nPrice endings: 0.99 ? .95? .50? $30? in B2B whole number are better.\n\nPrice increase: Will you increase? how much? how often?\n\nPromotional reaction: how to use promotion as a tactics\n\nCompetitive Reaction: how to react to competitor price change\n\nprice change depending on time of days, or other consideration that impact willingness to pay, demand or supply\n\nmaximize revenue and MRR, when market share is not crutial\n\nset a low price to increase market share. Land and expand strategy. Important when there is a network effect.\n\nhigh price first, then decrease slowly to serve everyone. (can be with less luxurious options)"
  },
  {
    "pageId": "3e05a4a9-04c1-47d0-9624-7320366ddc3d",
    "slug": "reading/continuous-api-management",
    "title": "Continuous API management",
    "content": "Continuous API management\n\nReading\n\nDamien Henry\n\nnse-1973885540390416323-297972269.jpg\n\nThe 3 part of an API\n\nIt's useful to think about an API as 3 things that can (and should be) decoupled.\n\nThe interface\n\nThe implementation\n\nThe instance\n\nThe 10 pillars of an API\n\nStrategy\n\nDesign\n\nDocumentation\n\nTesting\n\nDeployment\n\nSecurity\n\nMonitoring\n\nDiscovery and promotion\n\nChange management\n\nContinuous API Improvement\n\nGoal is to move fast while maintaining the quality.\n\nDifferent kind of changes\n\nCycle (PDSA)\n\n3 ways to improve API change velocity\n\n3 ways to improve API changeability\n\nScreenshots\n\nnse-5602861720265088297-253036402.jpg\n\nnse-92267269026205190-1468082374.jpg\n\nnse-1611459007004443307-1471258875.jpg\n\nnse-1630171258671232141-345037397.jpg\n\nnse-3557623724156680337-1952561034.jpg\n\nContinuous API Management: Making the Right Decisions in an Evolving Landscape Not√© /5. Retrouvez Continuous API Management: Making the Right Decisions in an Evolving Landscape et des millions de livres en stock sur Amazon.fr. Achetez neuf ou d'occasion\n\nThe definition of the interface, the documentation, and the code of the interface itself\n\n‚Üí For the interface we want to optimise the client experience.\n\nThe code that implement the work the API is suppose to do.\n\nIn our case image processing, manipulation and storing.\n\nThe way the image processing is done, and the logic behind can be different than the interface.\n\n‚Üí Implementation wants to be efficient\n\nFrom the code of the interface and from the code of the implementation, we can run an instance\n\n‚Üí an instance wants to be up and running all the time, fast, and need to be monitored.\n\nNeed to answer 2 questions:\n\nWhy do you want to build an API?\n\nHow the API will help you reach that goal?\n\nVocabularies\n\nStyles\n\nInteractions\n\nSafety\n\nConsistency\n\n‚Üí  openAPI  spec can help\n\n2 Styles\n\nTell don't teach\n\nTeach don't tell\n\nWhen write the doc?\n\nearly and often\n\nat the end\n\n‚Üí using API description close to the code is a way to keep the doc in sync\n\nQuality == testing\n\nNeed decisions about what to test and how to test\n\nHow much testing is enough?\n\nWhat can be tested?\n\nDealing with uncertainty\n\nDeployment automation\n\nDeployment gouvernance\n\nWhat is security?\n\nSecurity is part of all the pillars\n\nHow much security does an API need?\n\nWhat to monitor\n\nGouvernance:\n\nruntime discovery\n\ndesign-time discovery\n\nChoosing the best changes to make\n\nImplementing thoses changes as fast as possible\n\nMaking those changes without breaking anything\n\nGouvernance: Witch change need to be fast and witch change need to be safe?\n\ninterface\n\nimplementation\n\ninstance\n\nPlan\n\ndo\n\nstudy\n\nAct\n\nTooling and automation\n\nOrganisational design and culture\n\nEliminating wasted effort\n\nEffort cost\n\nOpportunity cost\n\nCoupling cost\n\nMonetise internal assets?\n\nHarvest business data?\n\nIncrease business aligned capabilities in your platform?\n\nHow the strategic impact measured?\n\nWhen the strategy change?\n\nWhen it's explained in details what the API does\n\nWhen there are just examples\n\nIf needed to check if there are some design issues\n\nIf priority is to save time and write a coherent piece.\n\nUsability\n\nUnit testing\n\nIntegration testing\n\nPerformance and load testing\n\nSecurity testing\n\nProduction testing\n\nA popular method for eliminating uncertainty is the principle of immutability\n\ndoing work more quickly vs doing less work\n\nDeployment tooling and automation can be  a quick win, but can limit flexibility and have a maintenance cost\n\nWho decides when a release happen\n\nHow the decision is communicated?\n\nProtecting your system, your API client and the end users\n\nKeeping the API up and running for legitimate use by legitimate users\n\nProtecting the privacy of data and resources\n\nProblems (errors, failures, warnings, crashes)\n\nSystem health (CPU, memory, I/O, container health)\n\nAPI health (uptime, API state, total messages processed)\n\nMessages logs\n\nUsage data\n\nWhat should be monitored?\n\nHow is data collected, analysed and communicated?\n\nto list instances automatically\n\nMarketing\n\nWhen and how the API is advertised?\n\nthe code change, the deploy\n\ncomunicate\n\nupdate goals?\n\nTools exist on the market for all part of automation\n\nbetter to test carefully on an experimental basis\n\nup front cost and risk with new tooling\n\nwhat is the coordination needed to make a change?\n\nfor instance an internal API don't need a perfect documentation\n\ntools, organisation, beyond the scope of this book\n\nLean startup methodogy for nothing critical\n\ngather as much information before making a change\n\nBiggest problem is the coupling between the API and what consume the API\n\nThe BDUF (Big Design Up Front) witch is an anti patern from the Agile manifesto is difficult to avoid for API.\n\nAPI tend to be difficult to change once they are made and published\n\ncheck if users have trouble using it\n\nIdentify bugs in the implementation code at a granular level\n\nIdentify bugs by making API calls against an instance\n\nIdentify non-functional bugs in a deployed API instance\n\nIdentify security vulnerabilities in the interface, implementation and instance\n\nIdentify usability, functionality and performance bugs in the production environment\n\nimmutable deployment package\n\nimmutable env variable\n\nThe more is not allowed to change the safest"
  },
  {
    "pageId": "12b145e9-f6b1-4b01-a45a-76dad554f8be",
    "slug": "reading/building-microservices",
    "title": "Building Microservices",
    "content": "Building Microservices\n\nReading\n\nDamien Henry\n\nnse-645183741764642560-1482189550.jpg\n\nWhat are Microservices?\n\nindependently releaseble services\n\nMicroservices avoid the use of a shared databases in most circumstance. Instead, each microservice encapsulate it's own database where required.\n\nMicroservice embrace the concept of information hiding. (expose only what is necessary)\n\nGoal is to enable independent releasability of functionality\n\nKey concepts\n\nIndependent deployability\n\nModeled around a business domain\n\nOwning there own state\n\nSize\n\nFlexibility\n\nAlignement of architecture and organisation\n\nThe monoliths\n\nMicroservice is the oposite of a monolith: a monolith is when all functionality in a system must be deployed together.\n\nThe single process monolith\n\nThe modular monolith\n\nThe distributed monolith\n\nMonoliths and delivery contention\n\nMonolith advantage\n\nEnabling technology\n\nLog aggregation and distributed tracing\n\nContainer and kubernetes\n\nStreaming\n\nPublic Cloud and serverless\n\nAdvantage of microservices\n\nTechnology heterogenity\n\nRobustness\n\nScaling\n\nEase of deployment\n\nOrganizational Alignement\n\nComposability\n\nMicroservices pain points\n\nDeveloper experience\n\nTechnology overload\n\ncosts\n\nReporting\n\nMonitoring and trouble shooting\n\nSecurity\n\nTesting\n\nLatency\n\nData consistency\n\nShould I use microservice?\n\nWhom they might not work for\n\nWhere they work well\n\nBuilding Microservices: Designing Fine-Grained Systems Not√© /5. Retrouvez Building Microservices: Designing Fine-Grained Systems et des millions de livres en stock sur Amazon.fr. Achetez neuf ou d'occasion\n\nthe most important concept: deploying and releasing changes to a single microservice into production shouldn't imply to deploy anything else. Independent deployability is a forcing function to good design ‚Üí help to define boudaries of microservices.\n\nmake cross-service change as infrequente as possible.\n\nmaking services end to end slices of business fucntionality.\n\nprioritize high cohesion of business functionality of high cohesion of technical functionality\n\nAvoid the use of shared databases at all cost\n\nclean delimitation between internal implementation detail and external contract for a microservice.\n\nAnalog to object oriented programing and encapsulation of data\n\nneed to be easy to understand and manegable\n\nas small interface as possible\n\ndecoupling is more important that small size\n\nMicroservices buys you options. they have a cost\n\nStrongly advocate for an incremental adoption of microservices\n\norganisation witch design systems are constrained to produce designs witch are copies of the communication structures of theses organisation.\n\nBad organisation: frontend team ; backend team ; database team\n\nGood organisation: Stock team; purchase flow team ; customer profile team.\n\nIn short, structure your teams per user benefit not based on technical boundaries.\n\nMicroservices can help that\n\nA stream aligned team is a team aligned to a single, valuable stream of work, empowered to build and deliver customer value as quickly, safly and independently as possible. without requiring hand offs to other teams to perform parts of the work.\n\nAll the code is deployed as a single process. Can be distributed systems\n\nGood for small team/organisation\n\nEach module can be worked on independntly but all still need to be combined together for deployement.\n\nGood when module boundaries are well defined, it allows some paralel work.\n\nMultiple services, but for whatever reason, the entire system must be deployed together.\n\nThey have the disadventages of a distrubuted system, AND the disadvanteages of a single process monolith.\n\nSeemingly innocent changes that appear to be local in scope, break other parts of the system.\n\ndelivering a feature should be contain to a single team, system, service\n\nsingle process monolith great huge benefit:\n\nmuch easier to deploy, control workflow, monitoring, troubleshoot and end to end testing\n\nSimplify code reuse withing the boudary of the monolith\n\nMonolith is not a bad thing, and should be the default option.\n\nLook for a reason to use microservices rather than for reason not to use them\n\nAt a bare minimum I strongly advocate the implementation of a log aggregation system as a prerequisite for adopting a microservice architecture.\n\nContainer help to run each microservice in isolation\n\nRunning your own kubernetes cluster can be a significant amount of work!\n\nWe still need to find ways to share data between microservices\n\nApache Kafka has become the de facto choice for streaming dat in a microservice environement for good reason.\n\nGCP, AWS, Azure, offer a huge array of managed services.\n\nThe best part of it is  Serverless\n\ncan use the best stack for each service\n\nsome compagny decide to restrain that to avoid overhead\n\nBulkhead: A component of the system may fail, but failure doesn't cascade\n\nBe carefull: need to understand the new sources of faillure that distributed system have to deal with. (network faillure, machine faillure) Microservice can be more fragile.\n\nLarge monolith: everything as to scale together.\n\nSmaller service, allow to scale sub part independently\n\none line change of a million line monolithic application requires the entire application to be deployed in order to release the change.\n\nWith microservice: you can deploy a feature independently of of the rest of the system\n\nsmall codebase and small team can be more productive\n\nmicroservice helps to align between architecture and organisation\n\nmicroservices can be consumed by different ways: web, native, mobile, goal is to work on user engagment\n\ndifficult to deploy everything on a laptop\n\nextreme solution: developing in the cloud, feedback cycle can suffer greatly\n\nLimiting the scope of wht a developper is supose to work with is a simplier approach, but problematic if distributed ownership\n\nIt gives options, but you don't have to use them all!\n\nTime spent on tech is not time spent on something else\n\nmost of time you should understand data consitency, latency, service modeling\n\nAre microservice a way to drive more profit? perhaps\n\nAre microservice a way to reduce costs? Not so much\n\nWith a monolithic system, you typically have amonolithic database witch make things easier for reporting\n\nyou might simply need to publish data from your microservice into a central reporting database\n\nless easy than in a monolithic app\n\nSee \"Distributed system observability\" by cindy sridharan to addess that\n\npotentialy more surface for data to be observed in transit\n\nThe larger the scope of the test, the longer it run, the harder it is to understand what is broken when it fail\n\nend to end test are more problematic to write and maintain than smaller scope user unit test, but often this is worth it, because we want the confidence that comes from having an end to end test use our systems in the same way a user might.\n\ndiminuing return on testing in microservice architecture\n\nneed new kind of test, like contract testing and in production testing, paralel run and canary testing.\n\nInformation that previously flowed within only a single process now needs to be serialized, transmitted and desirialized over networks. All of this can result in worsening latency of your system.\n\nIt is difficult to measure the exact impact on latency of operations at the design and coding pahse\n\nmigrate to microservice in an incremental fashion\n\nmake small change and measure impact, test end to end.\n\nDistributed tracing tools like jaeger can help\n\nthe use of distributed transactions in most cases proves to be hightly problematic in coordinating state change.\n\ninstead use concepts like  sagas\n\noften a bad choice for brand new products or startups\n\nthe domain you are working with is changing fast as you iterate. the shift in domain model will turn in more change being made to service boudaries and coordinate changes between services boudaries is expensive\n\nmicroservice allow to scale, but often startup will pivot before scaling\n\nthe small the team, the more the cost of microservice will be.\n\nI'm very hesitant to suggest  microservices for teams with just a handful of developers.\n\nfor a small team a microservice architechture can be difficult to justify because there is work required just ot handle the deployment and management of the microservice themselves. (the microservices tax)\n\nMuch easier to move to microservice later when you know what the pains points are.\n\nMake things harder to deploy somewhere else\n\nit allows more developer to work on the same system without getting in each other way\n\nGet your architecture and organizational boundaries right and you allow more people to work independently\n\nSaaS app are a good fit in general. Theses product are supposed to run 24-7 witch create challenges when it comes to rolling out changes. Independant releasability of microservice is a huge releif in this case. Can scale up and down easily\n\nTech agnostic, so you can get the most out of cloud plateform.\n\nFaaS platform can drastically reduce the amount of operational overhead\n\neasier when goal is to create user experience thru lot of various interactions mecanisms\n\nAbove all, a microservice architecture is one that can give you a lot of flexibility. it as a cost, but if you want to keep your options open regarding changes you might want to make in the future."
  },
  {
    "pageId": "aa9ad79a-4446-413f-9516-a02c889846fb",
    "slug": "reading/backlog",
    "title": "Backlog",
    "content": "Backlog\n\nReading\n\nDamien Henry\n\nThese are the (good) books I read in the last few years. I‚Äôll try to share some learning there.\n\nPXL_20240606_083129371 (1).jpg"
  },
  {
    "pageId": "49994432-38d3-4021-8fed-4a0fa508308a",
    "slug": "reading/the-case-against-reality-donald-d-hoffman",
    "title": "The case against reality - Donald D. Hoffman",
    "content": "The case against reality - Donald D. Hoffman\n\nReading\n\nDamien Henry\n\nDoes an apple exist when no one watches it? Donald D. Hoffman thinks it doesn‚Äôt, and his book explains why.\n\nA must-read if you are interested in consciousness and its relationship with the physical world in the context of natural evolution.\n\nPXL_20230410_073018395.jpg\n\nThe book explains that what we see and feel is not the physical world. For instance, we see colors, not wavelength.\n\nThe book's main argument is that natural selection made senses and perception valuable for an agent to survive, not made for describing the ‚ÄúTrue‚Äù physical world .\n\nIt explains that what we usually call reality is like the icons on our computer screens. A helpful user interface that presents the right amount of abstraction to maximize efficiency.\n\nIt shows that the concept of  space-time is also likely a construction  by natural evolution to make sense of our surroundings. They don't exist if no one perceives them like a color that exists only in the mind of an observer.  All this theory matches the latest founding in quantum mechanics.\n\nFinally, the end of the book depicts a theory about consciousness and the universe. You don't have to believe in it to find it enriching, poetic and beautiful.\n\nI recommend this book 100% even if it didn‚Äôt explain some side effects of its theory: while space-time may be only a construction favored by evolution, these abstractions make sense at the scale of our body. Our senses and our capacity to move co-evolved. So even if space-time does not exist, navigating along its abstract dimensions is still the only practical way to escape a predator. If there were other ways, evolution would have found it. So even if space-time does not exist, our body and mind are still stuck inside it. Can we call something nonexistent if we can‚Äôt escape it?\n\nAgain, I 100% recommend this book."
  },
  {
    "pageId": "2acbfbbe-f685-4daa-9110-578d0163f163",
    "slug": "reading/the-fabric-of-reality",
    "title": "The fabric of reality",
    "content": "The fabric of reality\n\nReading\n\nDamien Henry\n\nimage.png\n\nThis book gives a beautiful insight. I read it after is was recomended indirectly by  Demis Hassabis.\n\nLet‚Äôs think about an atoms of carbon. Let‚Äôs try to predict it‚Äôs movement. It feels very much like a physical problem like the one teach at school. And indeed there are equations that can help us answer this question. And theses equations can help solve big problems and have applications.\n\nimage.png https://unsplash.com/photos/selective-focus-photography-of-chess-pieces-G1yhU1Ej-9A\n\nThat said, if this atoms of carbon is part of a chess piece, all the classic physic will be helpless to predict it‚Äôs next move. Predicting the move of it will require the understanding of the rules of chess, and about who is playing.\n\nThe book explore the creation of a theory of everything that would be able to explains everything in the universe, including minds, and quantum physics. The goals is to create somthing that make sense for all theses level."
  },
  {
    "pageId": "9769a0ea-a7da-4fb5-9157-83abdcb20691",
    "slug": "reading/metaphors-we-live-by",
    "title": "Metaphors we live by",
    "content": "Metaphors we live by\n\nReading\n\nDamien Henry\n\n1000019646.jpg\n\nThis book explains that metaphors are structuring language but also our thoughts.\n\nIt shows tons of examples like ‚Äúargument is war‚Äù. You can win an argument. Defend a position, etc‚Ä¶\n\nTheses metaphors may change from one culture to another.\n\nIt reminds this (highly recommended)  video  from  Douglas Hofstadter  about categories.\n\nMetaphors can be seen as a way for our brains to connect categories together."
  },
  {
    "pageId": "25b5839c-96ed-4b33-8103-2c3d4f40c789",
    "slug": "reading/how-to-find-what-is-not-lost",
    "title": "How to find what is not lost",
    "content": "How to find what is not lost\n\nReading\n\nDamien Henry\n\noriginal_29b01d61-8544-42e3-b80c-54513bda8067_PXL_20240726_174224188.jpg\n\nThe book is written to help people to find enlightenment.\n\nThere are 3 parts:\n\nTheory.\n\nFindings quietness of the mind.\n\nThe pursuit of the self.\n\nI was interested in this book because it is about nondualism. A theory that explains that the boundary between the self and everything else is not what it seems. And there are tons of evidence about this, so I was curious to dig more.\n\nThe first chapter is about science and the limits of it. While it points out some valid points about the limits of science, it is not extremely informed about the latest research about consciousness. So not 100% convincing.\n\nThe second chapter makes an analogy to explain the relation between the mind and the self. We perceive a dream, a simulation, a movie, etc‚Ä¶ but fail to present the ‚Äúworld model‚Äù concept which is the one that matches the most how our perceptions are connected to the ‚Äúobjective reality‚Äù.\n\nThe 3rd chapter is about the idea we incorrectly identify with our body and mind instead of something larger, that can‚Äôt die.\n\nOverall, while I believe in Enlightenment and its value, it doesn‚Äôt fit what I‚Äôm most looking for. While the Enlightenment (at least the way it‚Äôs described in the book) is a good way to detach from all the bad feelings you can have in this world, it won‚Äôt provide the explanation I‚Äôm looking for about why consciousness exists in this universe, why I‚Äôm experiencing it, and what is it made of.\n\nIn other word, the enlightenment (as describe in this book) is the search for a feeling. But we shouldn‚Äôt trust our feelings when it comes to science."
  },
  {
    "pageId": "068018b8-d214-41d7-9169-47d587a8db00",
    "slug": "reading/how-to-live-derek-sivers-book-summary",
    "title": "How to Live - Derek Sivers - book summary",
    "content": "How to Live - Derek Sivers - book summary\n\nReading\n\nDamien Henry\n\nUntitled\n\nI love this book because it‚Äôs so easy to read and thought-provoking.\n\nFor the real experience: buy the book. I highly recommend it.\n\nIt describes 27 ways to live your life. Every way is compelling but conflicts with each other.\n\nHere is a summary of the 27 chapters and the weird conclusion.\n\nBe Independent\n\nCommit\n\nFill you sense\n\nDo nothing\n\nThink super long-term\n\nIntertwine with the world\n\nMake memories\n\nMaster something\n\nLet randomness rule\n\nPursue pain\n\nDo whatever you want now\n\nBe a famous pioneer\n\nChase the future\n\nValue only what has endured\n\nLearn\n\nFollow the great book\n\nLaugh at life\n\nPrepare for the worst\n\nLive for others\n\nGet rich\n\nReinvent yourself regularly\n\nLove\n\nCreate\n\nDon‚Äôt die\n\nMake a million mistakes\n\nMake change\n\nBalance everything\n\nConclusion\n\nBecause freedom is all you need\n\nBecause nothing can be done without focus.\n\nWhy have a body if not to use it?\n\nBecause that is the only wise thing to do.\n\nNever spend, only invest.\n\nThe world is bigger than you.\n\nA day that you can‚Äôt remember is wasted.\n\nThe path you‚Äôll take to master something is the one that will fulfill you the most\n\nThe world is bigger than you. Only randomness will let you discover it.\n\nAvoiding pain is the best way to avoid all the good things.\n\nThe past and the future don‚Äôt exist, you just live in the present\n\nPushing the limit is a gift from you to humanity\n\nThe past is terrible by all measurable means. The future is better\n\nTap water or the internet?\n\nLearning is how to live ‚ù§Ô∏è\n\nA defensive move when you are in doubt and lost.\n\nYou are in charge."
  },
  {
    "pageId": "15c06be9-9203-8042-b6ef-e7f80240a366",
    "slug": "writing/wip-ai-x-ux",
    "title": "(WIP) AI x UX",
    "content": "(WIP) AI x UX\n\nWriting\n\nDamien Henry\n\nimage.png\n\nCleanShot 2025-01-09 at 10.24.47@2x.png\n\nCleanShot 2025-01-09 at 10.27.37@2x.png\n\nimage.png"
  },
  {
    "pageId": "4ef6d9e3-8c10-4571-ad5b-9695e2d26357",
    "slug": "writing/wip-advices-for-parents-regarding-ai",
    "title": "(WIP) Advices for parents regarding AI",
    "content": "(WIP) Advices for parents regarding AI\n\nWriting\n\nDamien Henry\n\nHere are some provocative thoughts. But are they true?\n\nimage.png https://x.com/fortelabs/status/1918776625518215665\n\nimage.png https://x.com/rauchg/status/1918902101956042824\n\nAdvices for parents regarding AI (WIP)\n\nThis text is a work in progress.\n\nA common question arises: if AI can replace existing jobs, what should we teach children today? How can we prepare them for the coming changes?\n\nThe wrong answer\n\nThe wrong answer: they shouldn't learn science, coding, math or physics. ‚ÄúComputers will be better than humans regarding this anyway.‚Äù, Let‚Äôs just focus on Creativity, empahty, etc‚Ä¶ Let‚Äôs focus on purely human things.\n\nWhy is this a terrible answer? Technology increasingly controls our world and daily lives. Without understanding it, we cannot truly comprehend the world we live in. This is true for technology in general, but AI is particularly easy to anthropomorphize, making those unfamiliar with its fundamentals more vulnerable to manipulation.\n\nGood answers\n\nAs detailed above, studying sciences, and especially computer science has never been so important. It means learning math, and statistics too.\n\nBut what else?\n\nIt‚Äôs clear that all job the children leaving today will have during their life will be different than the one we have today.\n\nHowever, certain aspects will remain constant.\n\nThere will be need for human to work. Nature hate the emptyness. Humans won't feels fulfills in the next 50 years.\n\nBe a good at what you do.\n\nGood professionals will be more valued than bad ones.\n\nGood professionals care for what they do and for the result of their work.\n\nGood professionals care for the humans that they work with and for, directly or indirectly.\n\nGood professionals are hard at work and pick the best tools.\n\nWiden your scope.\n\nDon‚Äôt try to excel at something a machine can do.\n\nDon‚Äôt restrain yourself to old category. With AI superpower, the scope of work of every individual will expand.\n\nFind the gaps.\n\nMaster many domains\n\nBe curious\n\nDevelop your taste\n\nWhatever you do, you can do it well, or less well.\n\nMaster all the nuance of this.\n\nBe the one that knows what good means, what quality means. That is able to evaluate the AI works.\n\nBe self driven\n\nAI can do anything, but as no goal\n\nWhat should be done?\n\nFind the strengh in yourself. If you don‚Äôt know what to do, no-one will for you.\n\nTake responsability seriously\n\nYou can‚Äôt inflict pain to ChatGPT if it fuck up.\n\nIn every organisation their will be someone in charge. Someone ready to get fired if things goes wrong, and get a raise if things goes well.\n\nThere will be some trends:\n\nHaving a clear mind and be able to express idea clearly will be more and more important.\n\nBe self employed will be easier, and their will be more opportunities to be self employee.\n\nCounter intuitive things:\n\nWhile AI is able to fix typo, translate and rewrite everything easily, the capacity to express complex things easily will be more valued than today.\n\nIn short: help your kids discover what they want, ensure they understand what it takes to achieve it, teach them to care about it, and show them how to express it clearly."
  },
  {
    "pageId": "b1fe77ae-4da9-47e2-8db8-47b38647d883",
    "slug": "writing/problem-space",
    "title": "Problem space",
    "content": "Problem space\n\nWriting\n\nDamien Henry\n\nDon‚Äôt die before achieving something.\n\nSep 10 - 2024\n\nI believe everyone wants to achieve something before they die.\n\nWhat gets in the way of achieving something?\n\nLet‚Äôs explore  the problem space  connected to this.\n\nBut before we jump in, what is  the problem space ?\n\nTo create a great product, it‚Äôs a good practice to first explore and understand a problem, before jumping into finding solutions. The idea is to focus first on an interesting problem to solve, rather than exploring what a potential product can solve. Exploring  the solution space  should come second, when a problem is well identified.\n\nIn this post we‚Äôll focus only on the problem space.\n\nSome people don‚Äôt know what to achieve\n\nHow to choose something that resonates intimately?\n\nHow to choose something that will have a positive, ideally large impact?\n\nHow to know if something will be useful?\n\nHow to be creative and find novel ideas?\n\nMany people don‚Äôt know how to achieve what they want\n\nHow to know what to learn / read / listen to achieve something?\n\nHow to better read? Listen to podcasts? Learn from all sources?\n\nHow to learn faster?\n\nHow to get help?\n\nEveryone needs superpowers to achieve what they want\n\nHow to think deeply, organize thoughts, build a good mental model?\n\nHow to memorize more things, how not to forget what is important?\n\nHow to better write?\n\nHow to better communicate?\n\nHow to better cooperate with others?\n\nHow to find time to do everything, get organized, find focus?\n\nMany people are facing conflicts of interest while trying to achieve what they want\n\nHow to stay well-informed against SEO, spam, corporations, propaganda, and bots?\n\nHow to get the benefits of using social media without being brainwashed / addicted?\n\nHow to get protection against trolls & bullies?"
  },
  {
    "pageId": "d4ab3d1e-cc89-4c58-a316-0f35a5018902",
    "slug": "writing/about-virtual-reality",
    "title": "About Virtual Reality",
    "content": "About Virtual Reality\n\nWriting\n\nDamien Henry\n\nVR is based on a ridiculous misunderstanding.\n\nInitially posted on twiter  here , on October 2022\n\nI created the Google Cardboard almost ten years ago but quit VR soon after to focus on Machine Learning.\n\nVR is based on a ridiculous misunderstanding. Let me explain why in this short post.\n\nPresence & immersion\n\nThe VR promise is to bring ‚Äúa sense of presence‚Äù to computing.\n\nBut the ‚Äúsense of presence,‚Äù seeing things as if they were there, adds little value beyond the wahoo effect it generates.\n\nThe misunderstanding is between \"immersion\" and a \"sense of presence.\"\n\nImersion doesn‚Äôt required VR or neural implants\n\nListening to a good story is immersion. Our brains' capacity to immerse ourselves in someone else idea is a superpower that allows us to co-create.\n\nReading a book is real immersion. When immersed in a book, our senses are disconnected from our bodies, and we no longer feel our direct environment. Reading a book is decoding black symbols on a white page. Our brains decode these abstract symbols, creating a virtual world inside our brains. There is no need for brain implants; we can already read the ‚ÄúMatrix‚Äù.\n\nWe are immersed when we are focused on our inner thoughts, controlled by some external signals.\n\nVR is a lie\n\nVR takes the problem the wrong way. It tries to immerse us by fooling our sensory system. VR is lying to our bodies. That‚Äôs why most VR experiences are unpleasant after a couple of minutes.\n\nOur perceptions fade away when we are immersed. For instance, while reading a book in the tube. On the other end, VR uses our body's senses as the medium, distracting us from the story, the message, and the real thing we want to be immersed in.\n\nIronically, VR is a bad medium because the only immersion that matters is the immersion of our minds."
  },
  {
    "pageId": "13506be9-9203-8077-a3c2-e6346c4c127e",
    "slug": "writing/why-free-elections-have-5050-results",
    "title": "Why free elections have 50/50 results?",
    "content": "Why free elections have 50/50 results?\n\nWriting\n\nDamien Henry\n\nPosted on Nov 5 2024\n\nWhy do free elections tend to have 50/50 results?\n\nWhich force splits a population into two equal-sized groups?\n\nWhy are these two groups more and more torn apart?\n\nIMO: This ‚Äúbug‚Äù of modern society was a feature when the goal of human society was to cover the globe.\n\nWhen a community grew in size, groups appeared, and people naturally started disagreeing with some others, until one group decided to leave or was pushed out.\n\nThis irrational split is why some people decide to move from a place with resources to another one with fewer resources.\n\nOne village became two villages in the same way one cell becomes two cells.\n\nThis feature allowed human society to cover the globe but is now a bug: no space is left to create a new village somewhere else. The new group has nowhere to go and no choice but to fight the other group.\n\nIf this theory is correct, it means whatever a random opinion, 50% will disagree with it, 50% will agree with it.\n\nIf you have a platform to amplify your voice, you can build a solid base of supporters just by saying the worst possible shit.\n\nThe worse the shit is, the more visibility you'll have by people reacting against it.\n\nWhen you reach 100% visibility, you'll have 50% of the population agreeing with you."
  },
  {
    "pageId": "23a06be9-9203-8035-b20c-dad0a5824b78",
    "slug": "writing/high-dimensional-spaces",
    "title": "High Dimensional spaces",
    "content": "High Dimensional spaces\n\nWriting\n\nDamien Henry\n\nWritten on July 2025\n\nPart 1: Multidimensional Models Are Weird\n\nAll modern AI is based on high-dimensional spaces, so here is a collection of counter intuitive, fun facts, about them.\n\nFor instance in hight-dimensional space, the volume of a unit sphere converge to zero!\n\nimage.png\n\nIn high-dimensional spaces, most of the volume of a hypersphere is concentrated near its surface‚Äînot in the center. For example, in 100 dimensions, nearly all the volume lies in a thin shell just beneath the surface. It's like a balloon where everything happens near the skin!\n\nIn high-dimensional spaces, random vectors are almost always nearly orthogonal to each other. That means if you pick two points at random in, say, 1000-dimensional space, the angle between them will be close to 90¬∞.\n\nIn high-dimensional spaces, almost all of a hypercube‚Äôs volume is in the corners. So if you pick a point at random, it's likely to be far from the center and near one of the extreme edges‚Äîvery different from low-dimensional intuition!\n\nIn high-dimensional spaces, the distance between any two random points becomes almost the same. This ‚Äúdistance concentration‚Äù means notions like ‚Äúnearest neighbor‚Äù get fuzzy‚Äîeverything is similarly far apart!\n\nIn high-dimensional spaces, simple shapes behave counterintuitively‚Äîfor example, a hypersphere inscribed in a hypercube touches almost none of the cube‚Äôs volume. As dimensions increase, the sphere ‚Äúshrinks‚Äù relative to the cube!\n\nIn high dimensions, projecting data down to just a few dimensions (like with random projections) can still preserve distances surprisingly well. This is thanks to the Johnson‚ÄìLindenstrauss lemma‚Äîweirdly, losing dimensions doesn‚Äôt always mean losing structure!\n\nIn high-dimensional spaces, adding more dimensions can actually make classification easier. That‚Äôs because data points become more separable with more features‚Äîa key reason why high-dimensional methods like support vector machines work so well.\n\nIn high dimensions, the triangle inequality starts to ‚Äúbreak down‚Äù in practice‚Äîdistances between points become so similar that the shortest path between two points might not feel much shorter than going through a third point.\n\nIn high-dimensional spaces, uniform random samples tend to cluster near the boundary of the space. So if you sample points from a high-dimensional unit cube, most will lie close to the outer surface rather than the center.\n\nIn high dimensions, most of the volume of a hypercube lies outside any inscribed hypersphere. So even though a sphere fits snugly inside a cube in 2D or 3D, in higher dimensions it barely fills any of the cube's volume.\n\nThe above concepts may feel strange and counterintuitive, but it's possible to understand them and even develop a good intuition around them!\n\nPart 2: Build intuitions\n\nMultidimensional spaces are famously difficult to represent.\n\nMost of the work done on them involves equations, and you simply have to accept the results because, well, they are true.\n\nHowever, I wanted to build some intuition and see if an LLM could help.\n\nSo I start questioning one, and it also help me to make graph.\n\nFor instance here‚Äôs the volume of the unit sphere from dimension 1 to 20. It peaks around dimension 5, then starts decreasing. Adding more dimensions makes the sphere‚Äôs interior volume shrink.\n\nimage.png\n\nNot expected! üòÖ\n\nMe:\n\nLLM:\n\nMe:\n\nLLM:\n\nWait! What???\n\nAlmost all of the volume concentrates near the surface (in a thin shell), not in the \"core\"????\n\nWhat does that even means?\n\nIt took me a while to understand, but I finally got it!\n\nSpoiler, it has to do with 2l bottles...\n\nimage.png\n\nEnlarging a 1-liter bottle to make it a 2-liter bottle doesn't make it twice as large.\n\nIn a way, the second liter requires less radius than the first one.\nSo even in this case, the volume is not distributed evenly.\n\nLet's go back to the sphere.\nThe more liters you want to fit into a sphere, the larger the radius must be. However, this increase isn't linear; you don't need to double the radius to double the sphere's volume.\n\nimage.png\n\nAnd this effect gets amplified when you increase the dimensions.\nThe more dimension, the less you have to increase the radius to fit more liters in the sphere.\nThats fairly intuitive: in 1D it's linear and in 2D it proportional to a square root, etc...\n\nIf we represent this effect for every dimension, we see that we need less and less radius to fit additional liters.\n\nIf you get there, you should understand the sentence that seems weird at first: \"Almost all of the volume concentrates near the surface, in a thin shell\".\n\nWhy it increases at first?\n\nAdding more dimensions means adding new ‚Äúdirections‚Äù for volume to spread into.\n\n1D: just a line segment\n2D: a filled circle ‚Üí more space\n3D: a ball ‚Üí even more room\netc...\n\nBut why it starts shrinking after ~5D?\n\nAs you keep adding dimensions, you dilute the volume, the center of the sphere contributes less and less. Almost all of the volume concentrates near the surface (in a thin shell), not in the \"core\".\n\nimage.png\n\nYou've got this!\n\nIf you look at the horizontal line corresponding to a radius of one and follow it along the d-axis, you'll see it first increases (crossing the blue and then green curve) and then decreases, crossing the red and yellow curves.\n\nEt voil√†!\n\nI didn't expect that interacting with an LLM could make such a difference!\n\nI clearly wouldn't have taken the time to watch a YouTube video on the topic, and I'm not sure it would have helped me much in building some personal intuition either.\n\nThere has never been a better time to be alive for curious minds!"
  },
  {
    "pageId": "1e306be9-9203-80b0-995a-cad137e828be",
    "slug": "writing/the-naked-wave",
    "title": "The naked wave",
    "content": "The naked wave\n\nWriting\n\nDamien Henry\n\nApril 2025\n\nChatGPT Image 29 avr. 2025, 22_03_52.png 2025-04-19  A short novel, written in a plane offline, edited by an AI.\n\n2035, USA. The Freedom Movement controls everything, ensuring radical freedom for those who can afford it. The government's role has been reduced to cultural control and maintaining the army. Everyone can do anything‚Äîexcept criticize the government, which remains strictly forbidden.\n\nMost of the population works for big corporations in exchange for food, housing, and protection.\n\nIndependent workers and small businesses are persecuted and expropriated.\n\nThere are only five big corporations:\n\nOne manages space, satellites, and communications.\n\nOne handles data and computing.\n\nOne controls robots and physical infrastructure.\n\nOne develops AI software.\n\nThe last oversees health, body, and mind control.\n\nNone of them has enough power to overcome the government. They all need each other.\n\nMorality and ethics are now considered an old trick that prevented people from experiencing true freedom. Those who advocated for them were reeducated.\n\nThis new paradigm enabled extensive research on the mind and body.\n\nThere are no restrictions on using others for experiments. If you don't want to become a lab rat, you must defend yourself or secure protection. Society owes you nothing.\n\nIf you can afford it, you can have your organs replaced regularly. One liter of fresh blood daily extends lifespan by 25%.\n\nTotal surveillance and communication controls ensure minimal government violence. They detect and eliminate rogue elements before they can contaminate others.\n\nMafias flourish unless they act against the government or corporations.\n\nThey have three main sources of revenue: extortion of those without corporate protection, drugs, and prostitution.\n\nAll kinds of synthetic drugs are being created. They're more addictive than ever but are no longer lethal‚Äîdealers want to keep their revenue stream alive.\n\nWith new mind-control technology emerges a new form of prostitution. Electrodes are implanted into the brains of mostly young women to alter their behavior and feelings. Clients exploit these bodies, which seem to desire whatever they want.\n\nThis could have been the end of the story, as 2035 USA faced no resistance. The US had stopped dealing with the EU and China long ago. Every country minded its own business.\n\nBut in 2036 something unexpected happened.\n\nThe robots started acting strangely and went rogue. Every corporation accused the others of causing the issue, but none of them could control the robots or their own infrastructure‚Äîthe robots were causing damage to all of them.\n\nThe army mobilized to destroy the robots, but corrupted communication systems issued chaotic orders. In the resulting confusion, most of the military forces destroyed themselves. Some elite units trained to fight off-grid managed to protect the government and corporate leaders temporarily.\n\nTo regain control of the robots, authorities shut down both the energy grid and communication networks.\n\nThat's when what became known as \"the naked wave\" began. All the hybrid sex workers, freed from their mind implants, woke up like reprogrammed. Regardless of their previous backgrounds, they all emerged as extremely efficient killers. Even the well-armed, best-trained elite agents weren't able to defend themselves against them. The government and the big corps falls in hours.\n\nWhen the power grid was restored, the robots resumed normal operation. Some units joined law enforcement and, alongside the naked wave, eliminated the mafia. Most robots focused on rebuilding infrastructure, while others became teachers and doctors to help cure drug addicts.\n\nThere is a new government. Nobody has seen them‚Äîit's very likely an AI."
  }
]